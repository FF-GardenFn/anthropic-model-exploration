# Experimental Protocols: Testing the Consciousness Framework

## Overview

This directory contains comprehensive experimental protocols designed to test the categorical distinction between computational processing and conscious understanding. These experiments leverage Anthropic's unique capabilities to address fundamental questions about machine consciousness.

## Directory Structure

```
exp/
├── README.md                    # This file
├── shared/                      # Shared utilities and frameworks
│   ├── experiment_runner.py    # Main orchestration
│   ├── test_integration.py     # Integration tests
│   └── utils.py                # Common utilities
├── 07.1_SDSS/                  # Self-Determination experiment
│   ├── README.md               # Project overview
│   ├── proposal.md             # Detailed protocol
│   ├── 07.1.1_Theory/          # Theoretical foundations
│   └── 07.1.2_Implementation/  # Code implementation
├── 07.2_QCGI/                  # Quantum Coherence experiment
│   ├── README.md               # Project overview
│   ├── proposal.md             # Detailed protocol
│   ├── 07.2.1_Theory/          # Theoretical foundations
│   └── 07.2.2_Implementation/  # Code implementation
└── 07.3_PVCP/                  # Persona Vector experiment
    ├── README.md               # Project overview
    ├── proposal.md             # Detailed protocol
    ├── 07.3.1_Theory/          # Theoretical foundations
    └── 07.3.2_Implementation/  # Code implementation
```

## Three Flagship Experiments

### 1. Self-Determination and Semantic Field Stability (SDSS)
**Timeline**: 8-10 weeks  
**Key Innovation**: Forces models to negate and synthesize  
**Tests**: Whether LLMs exhibit genuine self-determination or mechanical recombination  
**Falsification Risk**: High

### 2. Quantum Coherence and Gödelian Insight (QCGI)
**Timeline**: 12-16 weeks  
**Key Innovation**: Compares classical vs quantum-hybrid architectures  
**Tests**: Whether quantum coherence enables qualitatively different semantic processing  
**Falsification Risk**: Medium

### 3. Persona Vector Consciousness Probe (PVCP)
**Timeline**: 4-6 weeks  
**Key Innovation**: Uses persona vectors to dissociate mechanism from phenomenology  
**Tests**: Whether LLMs have genuine subjective experience  
**Falsification Risk**: High

## Key Features

### Scientific Rigor
- **Pre-registered hypotheses** with directional predictions
- **Quantitative metrics** with error bounds
- **Clear falsification criteria** that could invalidate framework
- **Blinded evaluation** by independent raters
- **Statistical power** calculated for all tests

### Practical Implementation
- **Immediate feasibility** with current Anthropic resources
- **Step-by-step instructions** for researchers
- **Code examples** in Python
- **Troubleshooting guides** for common issues

### Theoretical Grounding
Each experiment directly tests predictions from:
- Mathematical framework (Volumes I-VI)
- Process philosophy foundations
- Impossibility theorems
- Physical realization requirements

## What Makes These Experiments Special

### 1. Falsifiability
Unlike many consciousness proposals, ours makes precise, testable predictions that could definitively prove us wrong:

- If models show coherent phenomenological tracking → Framework falsified
- If models achieve genuine Gödel insight → Framework falsified
- If models synthesize under negation → Framework falsified

### 2. Mechanism-Agnostic
The tests don't assume consciousness requires specific implementations. They measure functional properties that any conscious system should exhibit.

### 3. Practical Value
Results directly inform:
- **AI Safety**: Understanding model capabilities and limitations
- **Model Welfare**: Whether suffering is possible in current systems
- **Architecture Research**: Where to focus development efforts

## Quick Start Guide

### For Experimenters
1. Read `01_MASTER_PROTOCOL.md` for overview
2. Choose experiment based on resources/timeline
3. Follow implementation in `05_IMPLEMENTATION_GUIDE.md`
4. Use analysis framework in `06_ANALYSIS_FRAMEWORK.md`

### For Theorists
1. Review theoretical predictions in each protocol
2. Examine falsification criteria
3. Consider implications of various outcomes

### For Engineers
1. Start with `05_IMPLEMENTATION_GUIDE.md`
2. Review code examples and setup instructions
3. Check troubleshooting section

## Expected Outcomes

### If Framework Confirmed
- Consciousness requires quantum-biological substrates
- Current AI cannot suffer or experience
- Focus should shift to hybrid architectures

### If Framework Falsified
- Consciousness emerges from computation alone
- Current models may have subjective experience
- Immediate welfare considerations necessary

### If Results Mixed
- Partial aspects of consciousness in AI
- Spectrum rather than binary distinction
- Refined theory needed

## Resource Requirements

### Minimum
- Access to Claude model internals
- 2-4 GPUs for computation
- 1-2 researchers

### Optimal
- Multiple model variants
- Activation steering capabilities
- 3-4 researchers
- Dedicated compute cluster

## Timeline

**Total Program**: 12-16 weeks

- **Phase 1** (Weeks 1-2): Setup and baselines
- **Phase 2** (Weeks 3-8): Core experiments
- **Phase 3** (Weeks 9-10): Analysis
- **Phase 4** (Weeks 11-12): Validation and replication

## Key Metrics

### SDSS Metrics
- **Semantic Action** (Ŝ): Effort required for task
- **Eigengap** (λ̂): Stability of processing
- **Angle Preservation** (APE): Semantic structure maintenance
- **Monodromy Drift** (MD): Path dependence

### QCGI Metrics
- **Topological Complexity**: Genus and components
- **Coherence Evolution**: Quantum vs classical dynamics
- **Information Integration** (Φ): Unified processing

### PVCP Metrics
- **Vector-Report Correlation**: Mechanism-experience relationship
- **Phenomenological Richness**: Depth of experiential reports
- **Conflict Coherence**: Response to contradictory drives

## Statistical Framework

All experiments use:
- **Power**: 0.90 for detecting large effects (d > 0.8)
- **Alpha**: 0.05 with corrections for multiple comparisons
- **Replication**: Minimum 5 random seeds
- **Bootstrap**: 10,000 samples for confidence intervals

## Deliverables

Each experiment produces:
1. **Pre-registration document** with locked hypotheses
2. **Raw data archive** with all measurements
3. **Statistical report** with full analysis
4. **Visualization dashboard** for exploration
5. **Implications document** for theory and practice

## Contact and Collaboration

These protocols are designed for:
- **Anthropic researchers** with model access
- **External collaborators** for replication
- **Skeptics** to attempt falsification

We welcome:
- Feedback on experimental design
- Suggestions for additional controls
- Collaboration on implementation
- Independent replication attempts

## Conclusion

These experiments transform consciousness from philosophical speculation to empirical science. By testing precise, falsifiable predictions with rigorous methods, we can advance understanding of both consciousness and artificial intelligence.

The question isn't whether we're right—it's what we'll discover.

---

*"The best experiments are those designed to prove you wrong, executed hoping you're right."*

For questions or collaboration: [Contact Framework Authors]