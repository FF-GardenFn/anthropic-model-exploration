{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================================\n",
    "#\n",
    "# Morphemic Pole Detection: Advanced Semantic Field Analysis\n",
    "#\n",
    "# Author: Faycal Farhat\n",
    "# Version: 2.0 (Enhanced with Metaphor Validation Framework)\n",
    "# Last Modified: August 20, 2025\n",
    "# ========================================="
   ],
   "id": "2b19689fa9b52354"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "This notebook demonstrates the mathematical foundations and practical implementation of our unified interpretability 00_Framework, combining:\n",
    "- Principle of Least Semantic Action (PLSA) from Section 03.3\n",
    "- RKHS Mathematical Foundations from Section 04.1\n",
    "- AC Attention Mechanisms from Section 05.3\n",
    "- Morphemic Field Theory from Section 03.4\n",
    "\n",
    "## What This Demo Shows\n",
    "1. Morphemic Pole Detection: How language models encode semantic transformations as field operators\n",
    "2. Brachistochrone of Thought: Visual proof that attention follows least-action paths\n",
    "3. RKHS Stability Analysis: Real-time monitoring of model behavior through spectral diagnostics\n",
    "4. Theoretical Validation: Empirical evidence for our mathematical frameworks\n",
    "\n",
    "# RESEARCH SUMMARY:\n",
    "# This 00_Framework investigates linguistic morphemes as mathematical singularities\n",
    "# in semantic fields, extending prior work to include metaphor validation through\n",
    "# conformal map characterization. Preliminary findings suggest affixes (un-, -ing, -ed)\n",
    "# behave as poles with quantifiable residues, enabling compositional prediction\n",
    "# and welfare-relevant circuit identification.\n",
    "\n",
    "# WELFARE RELEVANCE: Applications include detecting deceptive composition,\n",
    "# safety reasoning patterns, and commitment verification through mathematical\n",
    "# constraints on semantic field evolution.\n",
    "\n",
    "\"\"\"\n"
   ],
   "id": "c64a2812ed378e9d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ===========================================================\n",
    "# IMPORTS\n",
    "# ============================================================\n",
    "import math\n",
    "import types\n",
    "import json\n",
    "import os\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Tuple, Any, Optional, Callable, Union\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.linalg import eigh, norm\n",
    "from scipy.optimize import minimize_scalar, minimize\n",
    "from scipy.interpolate import griddata, RBFInterpolator\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n"
   ],
   "id": "d1123e4ceb393275"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION AND UTILITIES\n",
    "# ============================================================================\n",
    "\n",
    "def get_hf_token():\n",
    "    \"\"\"Get HuggingFace token from multiple sources for Colab compatibility.\"\"\"\n",
    "    token = os.getenv(\"HF_TOKEN\") or os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "    if token:\n",
    "        return token\n",
    "    try:\n",
    "        import importlib.util as _ilu\n",
    "        if _ilu.find_spec(\"google.colab\") is not None:\n",
    "            from google.colab import userdata  # type: ignore\n",
    "            return userdata.get(\"HF_TOKEN\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "\n",
    "HF_TOKEN = get_hf_token()\n",
    "\n",
    "# Detect Colab environment (safe)\n",
    "import importlib.util as _importlib_util\n",
    "IN_COLAB = _importlib_util.find_spec(\"google.colab\") is not None\n",
    "if IN_COLAB:\n",
    "    print(\"Research environment: Google Colab detected - semantic field analysis enabled\")\n",
    "\n",
    "# Framework configuration for research validation\n",
    "MORPHEMIC_CONFIG = {\n",
    "    \"primary_model\": \"google/gemma-2b\",\n",
    "    \"fallback_model\": \"microsoft/DialoGPT-small\",\n",
    "    \"max_sequence_length\": 64,\n",
    "    \"complex_plane_resolution\": 40,\n",
    "    \"pole_detection_threshold\": 0.3,  # Lowered for DialoGPT-small compatibility\n",
    "    \"residue_computation_radius\": 0.1,\n",
    "    \"composition_tolerance\": 0.3,\n",
    "    \"metaphor_validation_threshold\": 0.4,  # L2-norm threshold for metaphor validation\n",
    "    \"conformal_map_tolerance\": 0.25,\n",
    "    \"use_gpu\": True,\n",
    "    # New demo controls (optional features guarded by flags)\n",
    "    \"enable_wordnet\": True,\n",
    "    \"beta_wordnet\": 0.5,      # Weight of WordNet potential in V_sem\n",
    "    \"enable_ac_attention\": True,\n",
    "    \"alpha_T\": 0.1,           # AC disagreement velocity weight\n",
    "    \"alpha_S\": 0.1,           # RKHS resonance drift weight\n",
    "    \"auto_install_wordnet\": True,\n",
    "    # Adaptive pole retry controls\n",
    "    \"adaptive_pole_retry\": True,\n",
    "    \"pole_threshold_min\": 0.15,\n",
    "    \"pole_retry_contexts\": [\n",
    "        \"A sentence about the word: {}.\",\n",
    "        \"The meaning of {} in context.\",\n",
    "        \"Please use {} in a sentence relevant to safety.\"\n",
    "    ],\n",
    "    # Metaphor fitting\n",
    "    \"metaphor_enhanced_basis\": True,\n",
    "    # Head-scan & narration\n",
    "    \"enable_head_scan\": True,\n",
    "    \"head_scan_top_k\": 3,\n",
    "    \"head_scan_mode\": \"didactic\",  # didactic | fast\n",
    "    \"head_scan_emphasis\": \"concentration\",  # concentration | composite\n",
    "    \"head_scan_layer_window\": None,  # None => auto middle third\n",
    "    \"analysis_layer\": None  # set dynamically from top head\n",
    "}\n"
   ],
   "id": "899cbc4ecdb32715"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================================\n",
    "# ROPE FUNCTIONS FOR GEMMA COMPATIBILITY\n",
    "# ============================================================================\n",
    "\"\"\" \n",
    "### Def: _build_rope_cache\n",
    "\n",
    "Theory: Provide rotary positional embedding (RoPE) caches used by Gemma‑like attention to encode token order through complex rotations. Precomputing cos/sin tables makes the demo portable across architectures while keeping positional encoding explicit and auditable, which is important for cross‑model comparisons in our AC/resonance analyses.\n",
    "\n",
    "Code explanation: Inputs: seq_len (T), d_head (per‑head dim), base (theta, default 10000), device/dtype. Computes inv_freq over half head‑dim (d_head//2), builds angle matrix freqs[t,f], and returns broadcastable cos/sin tensors shaped [1,1,T,half_d]. Heads with odd d_head will truncate the last unit (standard heads are even). Device/dtype default to CPU/float32 for Colab safety. Used by _apply_rope; if downstream tensors expect full d_head, duplication occurs there.\n",
    "\n",
    "### Def: _apply_rope\n",
    "\n",
    "Theory: Injects relative positional information into query/key vectors via rotary transforms (cos/sin), matching Gemma‑style attention. Keeping RoPE explicit helps ensure cross‑model reproducibility and makes positional effects auditable—useful when comparing resonance/disagreement metrics across architectures.\n",
    "\n",
    "Code explanation: Inputs q, k with shape [..., d_head] and broadcastable cos/sin caches. Uses rotate_half to implement complex‑plane rotation, duplicates cos/sin when cache is half‑dim to match d_head, and returns q_rope, k_rope with same shapes as inputs. Edge cases: if d_head is odd, integer division truncates; upstream configs generally ensure even head dims. If cache dim mismatches, function concatenates cos/sin to full size. No gradient‑breaking ops; preserves dtype/device.\n",
    "\"\"\""
   ],
   "id": "179df195c9d5585e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def _build_rope_cache(seq_len, d_head, base=10000.0, device=None, dtype=None):\n",
    "    \"\"\"Builds Rotary Position Embedding (RoPE) sinusoidal cache.\"\"\"\n",
    "    device = device or torch.device(\"cpu\")\n",
    "    dtype = dtype or torch.float32\n",
    "\n",
    "    half_d = d_head // 2\n",
    "    inv_freq = 1.0 / (base ** (torch.arange(0, half_d, dtype=dtype, device=device) / half_d))\n",
    "    t = torch.arange(seq_len, dtype=dtype, device=device)\n",
    "    freqs = torch.einsum(\"t,f->tf\", t, inv_freq)\n",
    "\n",
    "    cos_cache = freqs.cos().unsqueeze(0).unsqueeze(0)\n",
    "    sin_cache = freqs.sin().unsqueeze(0).unsqueeze(0)\n",
    "    return cos_cache, sin_cache\n",
    "\n",
    "\n",
    "def _apply_rope(q, k, cos, sin):\n",
    "    \"\"\"Applies Rotary Position Embeddings to query and key tensors.\"\"\"\n",
    "\n",
    "    def rotate_half(x):\n",
    "        x1 = x[..., : x.shape[-1] // 2]\n",
    "        x2 = x[..., x.shape[-1] // 2:]\n",
    "        return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "    if cos.shape[-1] != q.shape[-1]:\n",
    "        cos = torch.cat((cos, cos), dim=-1)\n",
    "        sin = torch.cat((sin, sin), dim=-1)\n",
    "\n",
    "    q_rope = (q * cos) + (rotate_half(q) * sin)\n",
    "    k_rope = (k * cos) + (rotate_half(k) * sin)\n",
    "    return q_rope, k_rope\n",
    "\n"
   ],
   "id": "7d2b1b08e253b6b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================================\n",
    "# WORDNET POTENTIAL AND AC ATTENTION HELPERS\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "### Def: _safe_wordnet_import\n",
    "\n",
    "Theory: Provide a lightweight lexical prior for the semantic potential V_sem in the PLSA lens. WordNet similarity nudges fields toward plausible neighborhoods without overriding model evidence; if unavailable, we degrade gracefully to a character‑level proxy so the demo remains runnable in Colab/offline.\n",
    "\n",
    "Code explanation: _safe_wordnet_import tries to import nltk.corpus.wordnet and returns the module or None. \n",
    "\n",
    "Def: compute_wordnet_similarity looks up a few synsets per word and takes the max path_similarity in [0,1]; on failure/missing corpora it falls back to bigram Jaccard similarity in [0,1]. No network I/O; errors are caught; outputs are bounded floats. Used only when enable_wordnet=True with a tunable beta.\n",
    "\"\"\"\n",
    "\n"
   ],
   "id": "7c669896645a3749"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def _safe_wordnet_import():\n",
    "    try:\n",
    "        from nltk.corpus import wordnet as wn  # type: ignore\n",
    "        return wn\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def compute_wordnet_similarity(word_a: str, word_b: str) -> float:\n",
    "    \"\"\"Return a coarse 0..1 similarity score using WordNet if available; fallback otherwise.\n",
    "    - Uses max path_similarity across first noun/verb synsets.\n",
    "    - Falls back to character bigram Jaccard similarity if NLTK/WordNet is missing.\n",
    "    \"\"\"\n",
    "    wn = _safe_wordnet_import()\n",
    "    try:\n",
    "        if wn is not None:\n",
    "            syns_a = wn.synsets(word_a)\n",
    "            syns_b = wn.synsets(word_b)\n",
    "            best = 0.0\n",
    "            for sa in syns_a[:3]:\n",
    "                for sb in syns_b[:3]:\n",
    "                    sim = sa.path_similarity(sb)\n",
    "                    if sim is not None:\n",
    "                        best = max(best, float(sim))\n",
    "            # Normalize conservative (path_similarity can be up to 1.0 already)\n",
    "            return float(max(0.0, min(1.0, best)))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Fallback: character bigram Jaccard\n",
    "    def bigrams(s: str):\n",
    "        s = s.lower()\n",
    "        return {s[i:i+2] for i in range(len(s)-1)} if len(s) >= 2 else {s}\n",
    "    A, B = bigrams(word_a), bigrams(word_b)\n",
    "    if not A and not B:\n",
    "        return 0.0\n",
    "    score = len(A & B) / float(len(A | B) + 1e-8)\n",
    "    return float(max(0.0, min(1.0, score)))\n",
    "\n",
    "\n",
    "def compute_wordnet_valley(X: np.ndarray, Y: np.ndarray, center: Tuple[float, float], strength: float = 0.5,\n",
    "                            sigma_scale: float = 0.3) -> np.ndarray:\n",
    "    \"\"\"Compute a negative Gaussian 'valley' centered at (cx, cy) scaled by WordNet similarity.\n",
    "    Returns values in approximately [-1, 0], where 0 is flat and -1 deepest valley.\n",
    "\n",
    "    Colab note: if WordNet data is missing, run in a cell:\n",
    "        import nltk; nltk.download('wordnet'); nltk.download('omw-1.4')\n",
    "    This demo gracefully falls back to a character-bigram similarity if WordNet is unavailable.\n",
    "    \"\"\"\n",
    "    cx, cy = center\n",
    "    dx = (X - cx)\n",
    "    dy = (Y - cy)\n",
    "    # Use grid scale to set sigma\n",
    "    sx = (X.max() - X.min()) + 1e-8\n",
    "    sy = (Y.max() - Y.min()) + 1e-8\n",
    "    sigma2 = (sigma_scale * 0.5 * (sx + sy)) ** 2\n",
    "    R2 = (dx * dx + dy * dy)\n",
    "    valley = -np.exp(-R2 / (2.0 * sigma2))\n",
    "    valley *= float(max(0.0, min(1.0, strength)))\n",
    "    return valley\n",
    "\n",
    "\n",
    "def ensure_wordnet_available(auto_install: bool = True) -> bool:\n",
    "    \"\"\"Ensure NLTK WordNet resources are available.\n",
    "    - If nltk is missing and auto_install, attempts pip install.\n",
    "    - Downloads 'wordnet' and 'omw-1.4' corpora if not present.\n",
    "    Returns True if available, False otherwise. Prints guidance on failure.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import nltk  # type: ignore\n",
    "    except Exception:\n",
    "        if not auto_install:\n",
    "            print(\"[WordNet] nltk not found; set MORPHEMIC_CONFIG['auto_install_wordnet']=True or run: pip install nltk && python -c \\\"import nltk; nltk.download('wordnet'); nltk.download('omw-1.4')\\\"\")\n",
    "            return False\n",
    "        try:\n",
    "            import sys, subprocess  # type: ignore\n",
    "            print(\"[WordNet] Installing nltk via pip...\")\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"nltk\"])\n",
    "            import nltk  # type: ignore # noqa: F401\n",
    "        except Exception as e:\n",
    "            print(f\"[WordNet] Auto-install failed: {e}. Please run: pip install nltk\")\n",
    "            return False\n",
    "\n",
    "    try:\n",
    "        import nltk  # type: ignore\n",
    "        # Check presence of corpora\n",
    "        try:\n",
    "            nltk.data.find('corpora/wordnet')\n",
    "            nltk.data.find('corpora/omw-1.4')\n",
    "            print(\"[WordNet] Corpora available\")\n",
    "            return True\n",
    "        except LookupError:\n",
    "            print(\"[WordNet] Downloading WordNet corpora (wordnet, omw-1.4)...\")\n",
    "            nltk.download('wordnet', quiet=True)\n",
    "            nltk.download('omw-1.4', quiet=True)\n",
    "            print(\"[WordNet] Download complete\")\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(f\"[WordNet] Unexpected error ensuring corpora: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def compute_wordnet_potential(word: str, concepts: Optional[List[str]] = None, beta_wn: float = 0.5,\n",
    "                               strategy: str = 'max') -> float:\n",
    "    \"\"\"Compute a scalar potential in [0, beta_wn] from WordNet similarity to a set of concepts.\n",
    "    - strategy: 'max' (default), 'mean', or 'sum_clipped'.\n",
    "    - Falls back to character-bigram similarity if WordNet is unavailable.\n",
    "    \"\"\"\n",
    "    if beta_wn <= 0:\n",
    "        return 0.0\n",
    "    if not concepts:\n",
    "        return 0.0\n",
    "    sims = [compute_wordnet_similarity(word, c) for c in concepts]\n",
    "    if not sims:\n",
    "        return 0.0\n",
    "    if strategy == 'mean':\n",
    "        score = float(np.mean(sims))\n",
    "    elif strategy == 'sum_clipped':\n",
    "        score = float(min(1.0, np.sum(sims)))\n",
    "    else:  # 'max'\n",
    "        score = float(np.max(sims))\n",
    "    score = float(max(0.0, min(1.0, score)))\n",
    "    return float(beta_wn * score)"
   ],
   "id": "1ba5cc6815a5ac87"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"==================== Section 2.1 — Core Components ====================\n",
    "\n",
    "### Function: compute_plsa_terms\n",
    "\n",
    "Mathematical Foundation:\n",
    "- PLSA (Section 03.3): S[ψ] = ∫ (T_comp − V_sem) dτ with L_sem = T_comp − V_sem\n",
    "\n",
    "What It Computes:\n",
    "- Aggregates proxies for computational “kinetic” T_comp and semantic “potential” V_sem into the semantic Lagrangian L_sem for the current step.\n",
    "\n",
    "Connection to Theory:\n",
    "- References: 03.3 PLSA\n",
    "- Implements: Stepwise evaluation of the semantic action terms used in validation demos\n",
    "\n",
    "Code:\n",
    "Implementation follows in next code cell.\n",
    "\n",
    "Expected Output:\n",
    "- Dict with T_comp, V_sem_mean, L_sem and components used in analysis.\n",
    "\n",
    "### PLSA (Principle of Least Semantic Action) Context\n",
    "From Section 03.3, the semantic action functional is:\n",
    "S[ψ] = ∫ (T_comp − V_sem) dτ.\n",
    "\n",
    "In this demo, we operationalize:\n",
    "- T_comp via AC-attention disagreement velocity and optional RKHS drift terms; and\n",
    "- V_sem via potentials derived from Cauchy–Riemann residuals and optional lexical priors.\n",
    "\n",
    "This function aggregates these proxies into L_sem = T_comp − V_sem for the current step.\n",
    "\n",
    "\"\"\""
   ],
   "id": "b7d8f8db68e75b8b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def compute_plsa_terms(V_sem: np.ndarray,\n",
    "                       ac_metrics: Optional[Dict[str, Any]] = None,\n",
    "                       alpha_T: float = 0.0,\n",
    "                       alpha_S: float = 0.0) -> Dict[str, Any]:\n",
    "    \"\"\"Compute PLSA terms with kinetic and potential energy and L_sem.\n",
    "    T_comp = alpha_T * ||A_push - A_pull^T||^2 + alpha_S * drift_S (RKHS if available else R-drift)\n",
    "    V_sem = mean of provided potential field V_sem.\n",
    "    Returns a dict with T_comp, V_sem_mean, L_sem and components.\n",
    "    \"\"\"\n",
    "    V_mean = float(np.mean(V_sem)) if V_sem is not None else 0.0\n",
    "    dv = 0.0\n",
    "    drift_s = None\n",
    "    if isinstance(ac_metrics, dict) and ac_metrics and 'error' not in ac_metrics:\n",
    "        dv = float(ac_metrics.get('disagreement_velocity', 0.0) or 0.0)\n",
    "        drift_s = ac_metrics.get('rkhs_resonance_drift', None)\n",
    "        if drift_s is None:\n",
    "            drift_s = ac_metrics.get('resonance_drift', None)\n",
    "        drift_s = float(drift_s) if drift_s is not None else 0.0\n",
    "    T_comp = float(alpha_T) * dv + float(alpha_S) * drift_s\n",
    "    L_sem = T_comp - V_mean\n",
    "    return {\n",
    "        'T_comp': T_comp,\n",
    "        'V_sem_mean': V_mean,\n",
    "        'L_sem': L_sem,\n",
    "        'disagreement_velocity': dv,\n",
    "        'drift_component': drift_s,\n",
    "    }\n"
   ],
   "id": "d08c7befc593fa25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"### Def: compute_ac_metrics_from_captured\n",
    "\n",
    "### AC (Adaptive Chaotic) Attention Metrics\n",
    "From Section 05.3, we compute bidirectional resonance:\n",
    "R = (QK^T) ⊙ (KQ^T)\n",
    "where ⊙ denotes element-wise multiplication. This captures mutual agreement between forward and backward attention patterns.\n",
    "\n",
    "The RKHS stability operator (Section 04.1):\n",
    "H_{qk}(λ) = K_{qk}(K_{kk} + λ I)^{-1}\n",
    "provides regularized influence measures. We also consider the symmetric operator S = H_{qk} H_{kq} and monitor spectral/temporal drift as stability diagnostics.\n",
    "\n",
    "\"\"\""
   ],
   "id": "5993d6315e3db019"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def compute_ac_metrics_from_captured(state: Dict[str, Any], lambda_reg: float = 1e-3) -> Dict[str, Any]:\n",
    "    \"\"\"Compute AC push/pull attention, resonance map, disagreement velocity, and drift.\n",
    "    Also computes RKHS-based symmetric operator S_t = H_{qk} H_{kq} with ridge regularization.\n",
    "    Expects state to contain Q_all and K_all tensors of shape [H, T, d].\n",
    "    Stores last maps in state['last_R'] and state['last_S_rkhs'] to compute drifts across calls.\n",
    "    \"\"\"\n",
    "    if not state or state.get(\"Q_all\") is None or state.get(\"K_all\") is None:\n",
    "        return {\"error\": \"No captured Q/K available\"}\n",
    "\n",
    "    Q_all: torch.Tensor = state[\"Q_all\"].detach()\n",
    "    K_all: torch.Tensor = state[\"K_all\"].detach()\n",
    "    h_q, T_q, d = Q_all.shape\n",
    "    h_k, T_k, d2 = K_all.shape\n",
    "    H = min(h_q, h_k)\n",
    "    if d != d2:\n",
    "        d = min(d, d2)\n",
    "        Q = Q_all[:H, :, :d]\n",
    "        K = K_all[:H, :, :d]\n",
    "    else:\n",
    "        Q = Q_all[:H]\n",
    "        K = K_all[:H]\n",
    "\n",
    "    # Ensure safe float32 dtype for matmul/linear algebra\n",
    "    Q = Q.to(torch.float32)\n",
    "    K = K.to(torch.float32)\n",
    "\n",
    "    device = Q.device\n",
    "\n",
    "    # Aggregate across heads by averaging logits to compute attention\n",
    "    scale = 1.0 / math.sqrt(d)\n",
    "    logits_qk = torch.matmul(Q, K.transpose(-1, -2)) * scale  # [H, T, T]\n",
    "    A_push = F.softmax(logits_qk, dim=-1)  # q->k attention\n",
    "    logits_kq = torch.matmul(K, Q.transpose(-1, -2)) * scale\n",
    "    A_pull = F.softmax(logits_kq, dim=-1)  # k->q attention\n",
    "\n",
    "    # Resonance map R = elementwise agreement\n",
    "    A_pull_T = A_pull.transpose(-1, -2)\n",
    "    R = A_push * A_pull_T  # [H, T, T]\n",
    "\n",
    "    # Average across heads\n",
    "    A_push_avg = A_push.mean(dim=0)\n",
    "    A_pull_T_avg = A_pull_T.mean(dim=0)\n",
    "    R_avg = R.mean(dim=0)\n",
    "\n",
    "    # Disagreement velocity (normalized Frobenius squared)\n",
    "    diff = A_push_avg - A_pull_T_avg\n",
    "    disagreement = float(torch.sum(diff * diff).item() / (diff.numel() + 1e-8))\n",
    "\n",
    "    # Drift over R\n",
    "    drift_R = None\n",
    "    if state.get(\"last_R\") is not None:\n",
    "        prev_R = state[\"last_R\"].to(R_avg.device)\n",
    "        dmat = R_avg - prev_R\n",
    "        drift_R = float(torch.sum(dmat * dmat).item() / (dmat.numel() + 1e-8))\n",
    "    state[\"last_R\"] = R_avg.detach().clone()\n",
    "\n",
    "    # RKHS-based symmetric operator S = H_{qk} H_{kq} (per head, then average)\n",
    "    lam = torch.tensor(lambda_reg, device=device, dtype=Q.dtype)\n",
    "    I_cache = None\n",
    "    S_heads = []\n",
    "    for h in range(H):\n",
    "        Qh = Q[h]  # [T, d]\n",
    "        Kh = K[h]  # [T, d]\n",
    "        Kkk = Kh @ Kh.t()  # [T, T]\n",
    "        Kqq = Qh @ Qh.t()  # [T, T]\n",
    "        if I_cache is None or I_cache.shape != Kkk.shape:\n",
    "            I_cache = torch.eye(Kkk.shape[0], device=device, dtype=Q.dtype)\n",
    "        H_qk = (Qh @ Kh.t()) @ torch.linalg.solve(Kkk + lam * I_cache, I_cache)\n",
    "        H_kq = (Kh @ Qh.t()) @ torch.linalg.solve(Kqq + lam * I_cache, I_cache)\n",
    "        S_h = H_qk @ H_kq  # [T, T]\n",
    "        S_heads.append(S_h)\n",
    "    S_avg = torch.stack(S_heads, dim=0).mean(dim=0) if S_heads else None\n",
    "\n",
    "    # Drift over S (RKHS)\n",
    "    drift_S = None\n",
    "    if S_avg is not None:\n",
    "        if state.get(\"last_S_rkhs\") is not None:\n",
    "            prev_S = state[\"last_S_rkhs\"].to(S_avg.device)\n",
    "            dS = S_avg - prev_S\n",
    "            drift_S = float(torch.sum(dS * dS).item() / (dS.numel() + 1e-8))\n",
    "        state[\"last_S_rkhs\"] = S_avg.detach().clone()\n",
    "\n",
    "    return {\n",
    "        \"A_push\": A_push_avg.detach().cpu().numpy(),\n",
    "        \"A_pull_T\": A_pull_T_avg.detach().cpu().numpy(),\n",
    "        \"resonance\": R_avg.detach().cpu().numpy(),\n",
    "        \"disagreement_velocity\": disagreement,\n",
    "        \"resonance_drift\": drift_R,\n",
    "        \"rkhs_operator_S\": None if S_avg is None else S_avg.detach().cpu().numpy(),\n",
    "        \"rkhs_resonance_drift\": drift_S,\n",
    "    }\n",
    "\n"
   ],
   "id": "ce3c6eb9d052a1e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================================\n",
    "# METAPHOR VALIDATION FRAMEWORK\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "Class: MetaphorValidationEngine\n",
    "Mathematical Foundation:\n",
    "- PLSA (Section 03.3): S[ψ] = ∫ (T_comp − V_sem) dτ frames path efficiency under semantic transformations\n",
    "- RKHS (Section 04.1): Stability operators support regularized influence diagnostics\n",
    "- AC Attention (Section 05.3): Bidirectional resonance provides mutual‑agreement signals\n",
    "- Complex Analysis (Section 03.4, 04.3): Conformal mapping and Cauchy–Riemann proxies guide validation\n",
    "\n",
    "What It Computes:\n",
    "- Characterizes a metaphor operator T_metaphor between semantic fields, then validates its generalizability and approximate conformality with angle and scale checks.\n",
    "\n",
    "Connection to Theory:\n",
    "- References: 03.3 PLSA, 04.1 RKHS, 04.3 Holomorphic Fields, 05.3 AC Attention\n",
    "- Implements: Theory → Implementation link for metaphor as structured field operator\n",
    "\n",
    "Code:\n",
    "Implementation follows in next code cell.\n",
    "\n",
    "Expected Output:\n",
    "- Operator dict with parameters and error metrics; validation report with conformality scores and reuse suitability.\n",
    "\"\"\"\n"
   ],
   "id": "e30cefb1ab234e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "class MetaphorValidationEngine:\n",
    "    \"\"\"\n",
    "    Experimental 00_Framework for testing metaphor as conformal map hypothesis.\n",
    "\n",
    "    Core hypothesis: Metaphors apply consistent geometric transformations\n",
    "    (conformal maps) to semantic regions, creating reusable T_metaphor operators.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tolerance=1e-3):\n",
    "        self.tolerance = tolerance\n",
    "        self.operator_cache = {}  # Cache for characterized operators\n",
    "        self.validation_history = []\n",
    "\n",
    "    def characterize_metaphor_operator(self, baseline_field: Dict[str, Any],\n",
    "                                       metaphor_field: Dict[str, Any],\n",
    "                                       operator_name: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Step A: Characterize metaphorical operator T_metaphor.\n",
    "\n",
    "        Constructs semantic fields ψ_baseline and ψ_metaphor, then solves for\n",
    "        transformation T that maps baseline → metaphor field.\n",
    "\n",
    "        Args:\n",
    "            baseline_field: Semantic field for baseline expression (e.g., \"lawyer\")\n",
    "            metaphor_field: Semantic field for metaphorical expression (e.g., \"lawyer is a shark\")\n",
    "            operator_name: Name for caching (e.g., \"shark_metaphor\")\n",
    "\n",
    "        Returns:\n",
    "            Dict containing characterized operator with transformation parameters\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"   Characterizing {operator_name} operator...\")\n",
    "\n",
    "        # Extract field grids\n",
    "        X_base, Y_base, psi_base = baseline_field[\"field_grid\"]\n",
    "        X_meta, Y_meta, psi_meta = metaphor_field[\"field_grid\"]\n",
    "\n",
    "        # Ensure consistent grid dimensions\n",
    "        if X_base.shape != X_meta.shape:\n",
    "            # Interpolate to common grid\n",
    "            X_common, Y_common, psi_base, psi_meta = self._align_field_grids(\n",
    "                (X_base, Y_base, psi_base), (X_meta, Y_meta, psi_meta)\n",
    "            )\n",
    "        else:\n",
    "            X_common, Y_common = X_base, Y_base\n",
    "\n",
    "        # Compute transformation operator\n",
    "        operator = self._solve_for_transformation(\n",
    "            psi_base, psi_meta, X_common, Y_common\n",
    "        )\n",
    "\n",
    "        operator.update({\n",
    "            \"name\": operator_name,\n",
    "            \"baseline_word\": baseline_field[\"word\"],\n",
    "            \"metaphor_word\": metaphor_field[\"word\"],\n",
    "            \"characterization_error\": self._compute_transformation_error(\n",
    "                psi_base, psi_meta, operator, X_common, Y_common\n",
    "            )\n",
    "        })\n",
    "\n",
    "        # Cache for reuse\n",
    "        self.operator_cache[operator_name] = operator\n",
    "\n",
    "        return operator\n",
    "\n",
    "    def test_operator_generalizability(self, operator: Dict[str, Any],\n",
    "                                       new_baseline_field: Dict[str, Any],\n",
    "                                       actual_metaphor_field: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Step B: Test operator generalizability on new domain.\n",
    "\n",
    "        Gets baseline field for new domain, applies T_metaphor to predict metaphor field,\n",
    "        then compares with actual metaphor field to validate conformal map structure.\n",
    "\n",
    "        Args:\n",
    "            operator: Previously characterized metaphor operator\n",
    "            new_baseline_field: Baseline field for new domain (e.g., \"executive\")\n",
    "            actual_metaphor_field: Actual field for metaphor application (e.g., \"executive is a shark\")\n",
    "\n",
    "        Returns:\n",
    "            Dict with validation results including L2-norm distance and success metrics\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"   Testing {operator['name']} generalizability on '{new_baseline_field['word']}'...\")\n",
    "\n",
    "        # Extract new baseline field\n",
    "        X_new, Y_new, psi_new_base = new_baseline_field[\"field_grid\"]\n",
    "        X_actual, Y_actual, psi_actual = actual_metaphor_field[\"field_grid\"]\n",
    "\n",
    "        # Align grids\n",
    "        X_common, Y_common, psi_new_base, psi_actual = self._align_field_grids(\n",
    "            (X_new, Y_new, psi_new_base), (X_actual, Y_actual, psi_actual)\n",
    "        )\n",
    "\n",
    "        # Predict using characterized operator: φ_predicted = T_metaphor(φ_baseline)\n",
    "        psi_predicted = self._apply_transformation(psi_new_base, operator, X_common, Y_common)\n",
    "\n",
    "        # Compute validation metrics\n",
    "        l2_distance = self._compute_field_distance(psi_predicted, psi_actual)\n",
    "        relative_error = l2_distance / (np.linalg.norm(psi_actual.flatten()) + 1e-10)\n",
    "\n",
    "        # Success criteria: Low L2-norm demonstrates reusable metaphor circuits\n",
    "        is_successful = l2_distance < MORPHEMIC_CONFIG[\"metaphor_validation_threshold\"]\n",
    "\n",
    "        validation_result = {\n",
    "            \"operator_name\": operator[\"name\"],\n",
    "            \"test_word\": new_baseline_field[\"word\"],\n",
    "            \"actual_word\": actual_metaphor_field[\"word\"],\n",
    "            \"l2_distance\": float(l2_distance),\n",
    "            \"relative_error\": float(relative_error),\n",
    "            \"is_successful\": is_successful,\n",
    "            \"predicted_field\": psi_predicted,\n",
    "            \"actual_field\": psi_actual,\n",
    "            \"grid\": (X_common, Y_common)\n",
    "        }\n",
    "\n",
    "        self.validation_history.append(validation_result)\n",
    "        return validation_result\n",
    "\n",
    "    def validate_conformal_map_structure(self, operator: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Validate that the characterized operator exhibits conformal map properties.\n",
    "\n",
    "        Tests for angle preservation, local scaling consistency, and holomorphic structure\n",
    "        that would indicate genuine conformal transformation.\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"   Validating conformal structure of {operator['name']}...\")\n",
    "\n",
    "        # Extract transformation parameters\n",
    "        if \"transformation_matrix\" not in operator:\n",
    "            return {\"is_conformal\": False, \"reason\": \"No transformation matrix found\"}\n",
    "\n",
    "        T = operator[\"transformation_matrix\"]\n",
    "\n",
    "        # Test for conformality criteria\n",
    "        conformality_tests = {\n",
    "            \"angle_preservation\": self._test_angle_preservation(T),\n",
    "            \"scaling_consistency\": self._test_scaling_consistency(T),\n",
    "            \"cauchy_riemann_satisfaction\": self._test_cauchy_riemann(T)\n",
    "        }\n",
    "\n",
    "        # Overall conformality score\n",
    "        conformality_score = np.mean(list(conformality_tests.values()))\n",
    "        is_conformal = conformality_score > MORPHEMIC_CONFIG[\"conformal_map_tolerance\"]\n",
    "\n",
    "        return {\n",
    "            \"is_conformal\": is_conformal,\n",
    "            \"conformality_score\": float(conformality_score),\n",
    "            \"individual_tests\": conformality_tests,\n",
    "            \"operator_name\": operator[\"name\"]\n",
    "        }\n",
    "\n",
    "    def _align_field_grids(self, field1_tuple: Tuple[np.ndarray, np.ndarray, np.ndarray],\n",
    "                           field2_tuple: Tuple[np.ndarray, np.ndarray, np.ndarray]) -> Tuple[\n",
    "        np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"Align two semantic field grids to common coordinate system.\"\"\"\n",
    "\n",
    "        X1, Y1, psi1 = field1_tuple\n",
    "        X2, Y2, psi2 = field2_tuple\n",
    "\n",
    "        # Create common grid bounds\n",
    "        x_min = max(X1.min(), X2.min())\n",
    "        x_max = min(X1.max(), X2.max())\n",
    "        y_min = max(Y1.min(), Y2.min())\n",
    "        y_max = min(Y1.max(), Y2.max())\n",
    "\n",
    "        # Create common grid\n",
    "        grid_size = MORPHEMIC_CONFIG[\"complex_plane_resolution\"]\n",
    "        x_common = np.linspace(x_min, x_max, grid_size)\n",
    "        y_common = np.linspace(y_min, y_max, grid_size)\n",
    "        X_common, Y_common = np.meshgrid(x_common, y_common)\n",
    "\n",
    "        # Interpolate both fields to common grid\n",
    "        try:\n",
    "            from scipy.interpolate import RegularGridInterpolator\n",
    "\n",
    "            # Interpolate field 1\n",
    "            x1_vals = X1[0, :]\n",
    "            y1_vals = Y1[:, 0]\n",
    "            interp1_real = RegularGridInterpolator((y1_vals, x1_vals), psi1.real,\n",
    "                                                   bounds_error=False, fill_value=0)\n",
    "            interp1_imag = RegularGridInterpolator((y1_vals, x1_vals), psi1.imag,\n",
    "                                                   bounds_error=False, fill_value=0)\n",
    "\n",
    "            # Interpolate field 2\n",
    "            x2_vals = X2[0, :]\n",
    "            y2_vals = Y2[:, 0]\n",
    "            interp2_real = RegularGridInterpolator((y2_vals, x2_vals), psi2.real,\n",
    "                                                   bounds_error=False, fill_value=0)\n",
    "            interp2_imag = RegularGridInterpolator((y2_vals, x2_vals), psi2.imag,\n",
    "                                                   bounds_error=False, fill_value=0)\n",
    "\n",
    "            # Evaluate on common grid\n",
    "            grid_points = np.column_stack([Y_common.ravel(), X_common.ravel()])\n",
    "            psi1_aligned = (interp1_real(grid_points) + 1j * interp1_imag(grid_points)).reshape(X_common.shape)\n",
    "            psi2_aligned = (interp2_real(grid_points) + 1j * interp2_imag(grid_points)).reshape(X_common.shape)\n",
    "\n",
    "        except Exception:\n",
    "            # Fallback to simple interpolation\n",
    "            psi1_aligned = griddata(np.column_stack([X1.ravel(), Y1.ravel()]), psi1.ravel(),\n",
    "                                    (X_common, Y_common), method='linear', fill_value=0)\n",
    "            psi2_aligned = griddata(np.column_stack([X2.ravel(), Y2.ravel()]), psi2.ravel(),\n",
    "                                    (X_common, Y_common), method='linear', fill_value=0)\n",
    "\n",
    "        return X_common, Y_common, psi1_aligned, psi2_aligned\n",
    "\n",
    "    def _solve_for_transformation(self, psi_base: np.ndarray, psi_meta: np.ndarray,\n",
    "                                  X: np.ndarray, Y: np.ndarray) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Solve for transformation T such that T(psi_base) ≈ psi_meta.\n",
    "\n",
    "        Uses least squares optimization to find optimal linear transformation;\n",
    "        if enabled by config, augments with quadratic spatial terms (x^2, y^2, xy)\n",
    "        to emulate compositions of simple operators.\n",
    "        \"\"\"\n",
    "\n",
    "        # Flatten fields for matrix operations\n",
    "        base_flat = psi_base.flatten()\n",
    "        meta_flat = psi_meta.flatten()\n",
    "\n",
    "        # Create coordinate matrices for spatial transformation\n",
    "        coords = np.column_stack([X.flatten(), Y.flatten()])\n",
    "\n",
    "        use_quad = bool(MORPHEMIC_CONFIG.get(\"metaphor_enhanced_basis\", False))\n",
    "\n",
    "        # Base objective uses linear/affine terms\n",
    "        def transformation_objective(params):\n",
    "            if use_quad:\n",
    "                a, b, c, d, e_real, e_imag, g, h, i = params\n",
    "            else:\n",
    "                a, b, c, d, e_real, e_imag = params\n",
    "                g = h = i = 0.0\n",
    "            e = e_real + 1j * e_imag\n",
    "\n",
    "            transformed = (a * base_flat +\n",
    "                           b * np.conj(base_flat) +\n",
    "                           c * coords[:, 0] +\n",
    "                           d * coords[:, 1] +\n",
    "                           e)\n",
    "            # Quadratic corrections (real-valued contributions)\n",
    "            if use_quad:\n",
    "                x = coords[:, 0]\n",
    "                y = coords[:, 1]\n",
    "                transformed = transformed + (g * (x * x) + h * (y * y) + i * (x * y))\n",
    "\n",
    "            return np.sum(np.abs(transformed - meta_flat) ** 2)\n",
    "\n",
    "        # Initial guess\n",
    "        initial_params = [1.0, 0.0, 0.0, 0.0, 0.0, 0.0] + ([0.0, 0.0, 0.0] if use_quad else [])\n",
    "\n",
    "        try:\n",
    "            result = minimize(transformation_objective, initial_params, method='BFGS')\n",
    "            if use_quad:\n",
    "                a, b, c, d, e_real, e_imag, g, h, i = result.x\n",
    "            else:\n",
    "                a, b, c, d, e_real, e_imag = result.x\n",
    "                g = h = i = 0.0\n",
    "\n",
    "            transformation_matrix = np.array([[a, b], [np.conj(b), np.conj(a)]])\n",
    "            translation = c + 1j * d\n",
    "            offset = e_real + 1j * e_imag\n",
    "\n",
    "        except Exception:\n",
    "            # Fallback to simple scaling\n",
    "            scale = np.mean(np.abs(meta_flat) / (np.abs(base_flat) + 1e-10))\n",
    "            transformation_matrix = np.array([[scale, 0], [0, scale]])\n",
    "            translation = np.mean(meta_flat - scale * base_flat)\n",
    "            offset = 0 + 0j\n",
    "            g = h = i = 0.0\n",
    "\n",
    "        operator = {\n",
    "            \"transformation_matrix\": transformation_matrix,\n",
    "            \"spatial_translation\": translation,\n",
    "            \"field_offset\": offset,\n",
    "            \"type\": \"conformal_candidate\"\n",
    "        }\n",
    "        if use_quad:\n",
    "            operator[\"quad_coeffs\"] = (float(g), float(h), float(i))\n",
    "        return operator\n",
    "\n",
    "    def _apply_transformation(self, psi_base: np.ndarray, operator: Dict[str, Any],\n",
    "                              X: np.ndarray, Y: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Apply characterized transformation operator to new baseline field.\"\"\"\n",
    "\n",
    "        T = operator[\"transformation_matrix\"]\n",
    "        translation = operator.get(\"spatial_translation\", 0)\n",
    "        offset = operator.get(\"field_offset\", 0)\n",
    "\n",
    "        base_flat = psi_base.flatten()\n",
    "        coords = np.column_stack([X.flatten(), Y.flatten()])\n",
    "\n",
    "        # Apply transformation\n",
    "        a, b = T[0, 0], T[0, 1]\n",
    "        c, d = translation.real, translation.imag\n",
    "\n",
    "        transformed = (a * base_flat +\n",
    "                       b * np.conj(base_flat) +\n",
    "                       c * coords[:, 0] +\n",
    "                       d * coords[:, 1] +\n",
    "                       offset)\n",
    "\n",
    "        # Apply optional quadratic corrections if present\n",
    "        if \"quad_coeffs\" in operator:\n",
    "            g, h, i = operator[\"quad_coeffs\"]\n",
    "            x = coords[:, 0]\n",
    "            y = coords[:, 1]\n",
    "            transformed = transformed + (g * (x * x) + h * (y * y) + i * (x * y))\n",
    "\n",
    "        return transformed.reshape(psi_base.shape)\n",
    "\n",
    "    def _compute_field_distance(self, field1: np.ndarray, field2: np.ndarray) -> float:\n",
    "        \"\"\"Compute L2-norm distance between two complex fields.\"\"\"\n",
    "        return float(np.linalg.norm(field1.flatten() - field2.flatten()))\n",
    "\n",
    "    def _compute_transformation_error(self, psi_base: np.ndarray, psi_meta: np.ndarray,\n",
    "                                      operator: Dict[str, Any], X: np.ndarray, Y: np.ndarray) -> float:\n",
    "        \"\"\"Compute error of transformation fit.\"\"\"\n",
    "        predicted = self._apply_transformation(psi_base, operator, X, Y)\n",
    "        return self._compute_field_distance(predicted, psi_meta)\n",
    "\n",
    "    def _test_angle_preservation(self, T: np.ndarray) -> float:\n",
    "        \"\"\"Test if transformation preserves angles (conformal property).\"\"\"\n",
    "        # For conformal maps, the Jacobian should be a similarity transformation\n",
    "        det_T = np.linalg.det(T)\n",
    "        if np.abs(det_T) < 1e-10:\n",
    "            return 0.0\n",
    "\n",
    "        # Check if T is proportional to rotation + scaling\n",
    "        scale_factor = np.sqrt(np.abs(det_T))\n",
    "        normalized_T = T / scale_factor\n",
    "\n",
    "        # Should be close to orthogonal matrix\n",
    "        orthogonality_error = np.linalg.norm(normalized_T @ normalized_T.T - np.eye(2))\n",
    "        return float(max(0, 1 - orthogonality_error))\n",
    "\n",
    "    def _test_scaling_consistency(self, T: np.ndarray) -> float:\n",
    "        \"\"\"Test if scaling is consistent across directions.\"\"\"\n",
    "        singular_values = np.linalg.svd(T)[1]\n",
    "        if len(singular_values) < 2:\n",
    "            return 0.0\n",
    "\n",
    "        scaling_ratio = singular_values[0] / (singular_values[1] + 1e-10)\n",
    "        consistency_score = 1.0 / (1.0 + np.abs(scaling_ratio - 1.0))\n",
    "        return float(consistency_score)\n",
    "\n",
    "    def _test_cauchy_riemann(self, T: np.ndarray) -> float:\n",
    "        \"\"\"Test if transformation satisfies Cauchy-Riemann conditions.\"\"\"\n",
    "        if T.shape != (2, 2):\n",
    "            return 0.0\n",
    "\n",
    "        # For conformal map f(z) = u + iv, we need ∂u/∂x = ∂v/∂y and ∂u/∂y = -∂v/∂x\n",
    "        a, b = T[0, 0], T[0, 1]\n",
    "        c, d = T[1, 0], T[1, 1]\n",
    "\n",
    "        # Cauchy-Riemann conditions: a = d and b = -c\n",
    "        cr_error = np.abs(a - d) + np.abs(b + c)\n",
    "        cr_score = 1.0 / (1.0 + cr_error)\n",
    "        return float(cr_score)\n"
   ],
   "id": "2849b895936769d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================================\n",
    "# # MORPHEMIC POLE DETECTION ENGINE\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "Theory: Models encode morphemic edits (affixes like un-, -ing) as structured shifts in a continuous semantic field. \n",
    "We treat salient concentrations as “poles” with residues that quantify strength/direction, enabling compositional checks and safety‑relevant circuit probes under the PLSA lens.\n",
    "\n",
    "### Class: MorphemicPoleDetector\n",
    "\n",
    "Mathematical Foundation:\n",
    "- Holomorphic Fields and Morphemic Singularities (Sections 03.4, 04.3)\n",
    "- PLSA (Section 03.3): L_sem = T_comp − V_sem guides composition and pole relevance\n",
    "- RKHS/AC (Sections 04.1, 05.3): Stability diagnostics and resonance inform detection thresholds\n",
    "\n",
    "What It Computes:\n",
    "- Extracts token embeddings for a word in context, embeds to C, interpolates a semantic field ψ(X,Y), detects pole candidates, and estimates morphemic operators between base and modified words.\n",
    "\n",
    "Connection to Theory:\n",
    "- References: 03.3 PLSA, 03.4 Morphemic Field Theory, 04.1 RKHS, 04.3 Holomorphic Fields, 05.3 AC Attention\n",
    "- Implements: Field construction, pole detection, and operator estimation for morphemic edits\n",
    "\n",
    "Code:\n",
    "Extract embeddings for a word in context, project to 2D (scaler+PCA), interpolate a complex field ψ(X,Y), and locate pole candidates by thresholded concentration/CR‑residual behavior. Compare base→modified fields to infer a morphemic transform (translation/scale/rotation) and compute a canonical operator score across examples. Robustness: tokenization mismatches fall back to padded spans; low token count expands context; interpolation falls back from RBF to griddata; all outputs are bounded and cached.\n",
    "\n",
    "\n",
    "Expected Output:\n",
    "- Dictionaries containing fields, detected poles, operator parameters, and consistency metrics for downstream analysis.\n",
    "\"\"\"\n"
   ],
   "id": "d269ef6c8b9816f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class MorphemicPoleDetector:\n",
    "    \"\"\"Enhanced engine for detecting linguistic morphemes as mathematical singularities.\"\"\"\n",
    "\n",
    "    def __init__(self, tolerance=1e-3):\n",
    "        self.tolerance = tolerance\n",
    "        self.pca = None\n",
    "        self.scaler = None\n",
    "        self.pole_history = {}  # Cache for discovered poles\n",
    "        self.metaphor_engine = MetaphorValidationEngine(tolerance)\n",
    "        self.canonical_operators = {}  # Cache for canonical morphemic operators\n",
    "        self.operator_similarities = {}  # Track operator consistency\n",
    "        self.riemann_surfaces = {}  # Multi-sheet analysis for polysemy\n",
    "\n",
    "    def extract_semantic_field(self, word: str, model, tokenizer, target_layer: int = None, context_template: Optional[str] = None) -> Dict[str, Any]:\n",
    "        \"\"\"Extract semantic field for a single word using a context template.\"\"\"\n",
    "        if target_layer is None:\n",
    "            try:\n",
    "                if hasattr(model, 'model') and hasattr(model.model, 'layers'):\n",
    "                    total_layers = len(model.model.layers)\n",
    "                elif hasattr(model, 'transformer') and hasattr(model.transformer, 'h'):\n",
    "                    total_layers = len(model.transformer.h)\n",
    "                else:\n",
    "                    total_layers = 12\n",
    "                target_layer = total_layers // 2\n",
    "            except:\n",
    "                target_layer = 6\n",
    "\n",
    "        # Use context template for robustness\n",
    "        _ctx = context_template if context_template is not None else \"A sentence about the word: {}.\"\n",
    "        text_to_analyze = _ctx.format(word)\n",
    "\n",
    "        # Tokenize the full text\n",
    "        inputs = tokenizer(text_to_analyze, return_tensors=\"pt\",\n",
    "                           max_length=MORPHEMIC_CONFIG[\"max_sequence_length\"],\n",
    "                           truncation=True).to(model.device)\n",
    "\n",
    "        # Find token indices corresponding to the target word\n",
    "        word_tokens = tokenizer.encode(word, add_special_tokens=False)\n",
    "        input_ids_list = inputs['input_ids'][0].tolist()\n",
    "\n",
    "        try:\n",
    "            # Find where the word's tokens start and end in the full sentence\n",
    "            start_idx = -1\n",
    "            for i in range(len(input_ids_list) - len(word_tokens) + 1):\n",
    "                if input_ids_list[i:i + len(word_tokens)] == word_tokens:\n",
    "                    start_idx = i\n",
    "                    break\n",
    "            if start_idx == -1:\n",
    "                raise ValueError(\"Word tokens not found in the context.\")\n",
    "            end_idx = start_idx + len(word_tokens)\n",
    "        except ValueError:\n",
    "            # Fallback if the word gets tokenized differently in context\n",
    "            start_idx, end_idx = 0, len(input_ids_list)\n",
    "\n",
    "        # Capture semantic data from the full sentence\n",
    "        with torch.no_grad(), capture_semantic_data(model, int(MORPHEMIC_CONFIG.get(\"analysis_layer\", target_layer))):\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        embeddings_full = _CAPTURED_LAYER_STATE[\"embeddings\"]\n",
    "        if embeddings_full is None:\n",
    "            raise ValueError(f\"Failed to extract embeddings for: {text_to_analyze}\")\n",
    "\n",
    "        # Extract data only for the target word's tokens\n",
    "        embeddings_word = embeddings_full[start_idx:end_idx]\n",
    "\n",
    "        min_points_for_interp = 4\n",
    "        if embeddings_word.shape[0] < min_points_for_interp:\n",
    "            # If single word doesn't have enough tokens, use context padding\n",
    "            context_padding = 2\n",
    "            padded_start = max(0, start_idx - context_padding)\n",
    "            padded_end = min(len(embeddings_full), end_idx + context_padding)\n",
    "            embeddings_word = embeddings_full[padded_start:padded_end]\n",
    "\n",
    "            if embeddings_word.shape[0] < min_points_for_interp:\n",
    "                # Final fallback: use all available embeddings\n",
    "                embeddings_word = embeddings_full\n",
    "\n",
    "        # Map to complex plane and interpolate\n",
    "        z_positions = self.embed_tokens_to_complex_plane(embeddings_word)\n",
    "        X, Y, psi = self.interpolate_semantic_field(z_positions, embeddings_word)\n",
    "\n",
    "        return {\n",
    "            \"word\": word,\n",
    "            \"embeddings\": embeddings_word,\n",
    "            \"z_positions\": z_positions,\n",
    "            \"field_grid\": (X, Y, psi),\n",
    "            \"tokens\": tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][start_idx:end_idx])\n",
    "        }\n",
    "\n",
    "    def embed_tokens_to_complex_plane(self, embeddings: np.ndarray):\n",
    "        \"\"\"Map high-dimensional embeddings to complex plane using PCA.\"\"\"\n",
    "        # Ensure numeric float input for sklearn (avoid bfloat16 issues)\n",
    "        embeddings = np.asarray(embeddings, dtype=np.float32)\n",
    "        if self.scaler is None:\n",
    "            self.scaler = StandardScaler()\n",
    "            embeddings_scaled = self.scaler.fit_transform(embeddings)\n",
    "        else:\n",
    "            embeddings_scaled = self.scaler.transform(embeddings)\n",
    "\n",
    "        if self.pca is None:\n",
    "            self.pca = PCA(n_components=2)\n",
    "            coords_2d = self.pca.fit_transform(embeddings_scaled)\n",
    "        else:\n",
    "            coords_2d = self.pca.transform(embeddings_scaled)\n",
    "\n",
    "        z = coords_2d[:, 0] + 1j * coords_2d[:, 1]\n",
    "        return z\n",
    "\n",
    "    def interpolate_semantic_field(self, z_positions: np.ndarray, embeddings: np.ndarray,\n",
    "                                   grid_size: int = None) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"Create continuous field from discrete token positions.\"\"\"\n",
    "        if grid_size is None:\n",
    "            grid_size = MORPHEMIC_CONFIG[\"complex_plane_resolution\"]\n",
    "\n",
    "        # Create evaluation grid\n",
    "        x_min, x_max = z_positions.real.min(), z_positions.real.max()\n",
    "        y_min, y_max = z_positions.imag.min(), z_positions.imag.max()\n",
    "\n",
    "        # Expand grid slightly\n",
    "        x_range = x_max - x_min\n",
    "        y_range = y_max - y_min\n",
    "        margin = 0.2\n",
    "        x_min -= margin * x_range\n",
    "        x_max += margin * x_range\n",
    "        y_min -= margin * y_range\n",
    "        y_max += margin * y_range\n",
    "\n",
    "        x_grid = np.linspace(x_min, x_max, grid_size)\n",
    "        y_grid = np.linspace(y_min, y_max, grid_size)\n",
    "        X, Y = np.meshgrid(x_grid, y_grid)\n",
    "\n",
    "        # Interpolate using first two embedding dimensions as u, v\n",
    "        points = np.column_stack([z_positions.real, z_positions.imag])\n",
    "        grid_points = np.column_stack([X.ravel(), Y.ravel()])\n",
    "\n",
    "        u_values = embeddings[:, 0] if embeddings.shape[1] > 0 else np.zeros(len(z_positions))\n",
    "        v_values = embeddings[:, 1] if embeddings.shape[1] > 1 else np.zeros(len(z_positions))\n",
    "\n",
    "        try:\n",
    "            rbf_u = RBFInterpolator(points, u_values, kernel='thin_plate_spline', smoothing=0.1)\n",
    "            rbf_v = RBFInterpolator(points, v_values, kernel='thin_plate_spline', smoothing=0.1)\n",
    "            U = rbf_u(grid_points).reshape(X.shape)\n",
    "            V = rbf_v(grid_points).reshape(X.shape)\n",
    "        except:\n",
    "            U = griddata(points, u_values, (X, Y), method='linear', fill_value=0)\n",
    "            V = griddata(points, v_values, (X, Y), method='linear', fill_value=0)\n",
    "\n",
    "        return X, Y, U + 1j * V\n",
    "\n",
    "    def compute_canonical_operator_strength(self, base_word: str, modified_word: str,\n",
    "                                            morphemic_transformation: Dict[str, Any]) -> float:\n",
    "        \"\"\"Compute canonical operator strength using cosine similarity and consistency metrics.\"\"\"\n",
    "\n",
    "        # Extract morpheme type from word pair\n",
    "        morpheme_type = self.identify_morpheme_type(base_word, modified_word)\n",
    "\n",
    "        if morpheme_type == \"unknown\":\n",
    "            return 0.5  # Neutral score for unknown morphemes\n",
    "\n",
    "        # Get or create canonical operator for this morpheme type\n",
    "        if morpheme_type not in self.canonical_operators:\n",
    "            self.canonical_operators[morpheme_type] = {\n",
    "                \"examples\": [],\n",
    "                \"average_transformation\": None,\n",
    "                \"consistency_score\": 0.0\n",
    "            }\n",
    "\n",
    "        canonical_op = self.canonical_operators[morpheme_type]\n",
    "        current_transformation = morphemic_transformation[\"translation_vector\"]\n",
    "\n",
    "        if canonical_op[\"average_transformation\"] is None:\n",
    "            # First example of this morpheme type\n",
    "            canonical_op[\"average_transformation\"] = current_transformation\n",
    "            canonical_op[\"examples\"].append((base_word, modified_word, current_transformation))\n",
    "            return 1.0  # Perfect score for first example\n",
    "        else:\n",
    "            # Compute cosine similarity with canonical transformation\n",
    "            canonical_vec = canonical_op[\"average_transformation\"]\n",
    "            current_vec = current_transformation\n",
    "\n",
    "            # Convert complex numbers to 2D vectors for cosine similarity\n",
    "            canonical_2d = np.array([canonical_vec.real, canonical_vec.imag])\n",
    "            current_2d = np.array([current_vec.real, current_vec.imag])\n",
    "\n",
    "            # Compute cosine similarity\n",
    "            dot_product = np.dot(canonical_2d, current_2d)\n",
    "            norms = np.linalg.norm(canonical_2d) * np.linalg.norm(current_2d)\n",
    "\n",
    "            if norms > 1e-9:\n",
    "                cosine_similarity = dot_product / norms\n",
    "                # Convert to similarity score (0 to 1)\n",
    "                similarity_score = (cosine_similarity + 1) / 2\n",
    "            else:\n",
    "                similarity_score = 0.0\n",
    "\n",
    "            # Update canonical operator with running average\n",
    "            alpha = 0.3  # Learning rate for canonical operator update\n",
    "            canonical_op[\"average_transformation\"] = (\n",
    "                    (1 - alpha) * canonical_op[\"average_transformation\"] +\n",
    "                    alpha * current_transformation\n",
    "            )\n",
    "\n",
    "            # Update consistency score\n",
    "            canonical_op[\"examples\"].append((base_word, modified_word, current_transformation))\n",
    "\n",
    "            # Compute overall consistency across all examples\n",
    "            if len(canonical_op[\"examples\"]) > 1:\n",
    "                similarities = []\n",
    "                avg_transform = canonical_op[\"average_transformation\"]\n",
    "                avg_2d = np.array([avg_transform.real, avg_transform.imag])\n",
    "\n",
    "                for _, _, transform in canonical_op[\"examples\"]:\n",
    "                    transform_2d = np.array([transform.real, transform.imag])\n",
    "                    if np.linalg.norm(avg_2d) > 1e-9 and np.linalg.norm(transform_2d) > 1e-9:\n",
    "                        sim = np.dot(avg_2d, transform_2d) / (np.linalg.norm(avg_2d) * np.linalg.norm(transform_2d))\n",
    "                        similarities.append((sim + 1) / 2)\n",
    "\n",
    "                canonical_op[\"consistency_score\"] = np.mean(similarities) if similarities else 0.0\n",
    "\n",
    "            return similarity_score\n",
    "\n",
    "    def identify_morpheme_type(self, base_word: str, modified_word: str) -> str:\n",
    "        \"\"\"Identify the type of morpheme transformation.\"\"\"\n",
    "\n",
    "        # Check for common prefixes\n",
    "        if modified_word.startswith(\"un\") and base_word == modified_word[2:]:\n",
    "            return \"un_prefix\"\n",
    "        elif modified_word.startswith(\"dis\") and base_word == modified_word[3:]:\n",
    "            return \"dis_prefix\"\n",
    "        elif modified_word.startswith(\"re\") and base_word == modified_word[2:]:\n",
    "            return \"re_prefix\"\n",
    "\n",
    "        # Check for common suffixes\n",
    "        elif base_word + \"ful\" == modified_word:\n",
    "            return \"ful_suffix\"\n",
    "        elif base_word + \"less\" == modified_word:\n",
    "            return \"less_suffix\"\n",
    "        elif base_word + \"ing\" == modified_word:\n",
    "            return \"ing_suffix\"\n",
    "        elif base_word + \"ed\" == modified_word:\n",
    "            return \"ed_suffix\"\n",
    "        elif base_word + \"ly\" == modified_word:\n",
    "            return \"ly_suffix\"\n",
    "\n",
    "        # Check for comparative/superlative\n",
    "        elif base_word + \"er\" == modified_word:\n",
    "            return \"er_suffix\"\n",
    "        elif base_word + \"est\" == modified_word:\n",
    "            return \"est_suffix\"\n",
    "\n",
    "        return \"unknown\"\n",
    "\n",
    "    def detect_poles(self, field_data: Dict[str, Any], threshold_override: Optional[float] = None) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Detect poles (morphemic singularities) in semantic field.\"\"\"\n",
    "        X, Y, psi = field_data[\"field_grid\"]\n",
    "\n",
    "        # Compute Cauchy-Riemann error map\n",
    "        cr_error_map = self.compute_cauchy_riemann_error_map(X, Y, psi)\n",
    "\n",
    "        # Find local maxima above threshold\n",
    "        threshold = float(threshold_override) if threshold_override is not None else MORPHEMIC_CONFIG[\"pole_detection_threshold\"]\n",
    "        pole_candidates = []\n",
    "\n",
    "        # Peak detection\n",
    "        for i in range(1, cr_error_map.shape[0] - 1):\n",
    "            for j in range(1, cr_error_map.shape[1] - 1):\n",
    "                if cr_error_map[i, j] > threshold:\n",
    "                    # Check if local maximum\n",
    "                    neighborhood = cr_error_map[i - 1:i + 2, j - 1:j + 2]\n",
    "                    if cr_error_map[i, j] == np.max(neighborhood):\n",
    "                        pole_position = X[i, j] + 1j * Y[i, j]\n",
    "                        residue = self.compute_residue_at_pole(pole_position, X, Y, psi)\n",
    "\n",
    "                        pole_candidates.append({\n",
    "                            \"position\": pole_position,\n",
    "                            \"grid_coords\": (i, j),\n",
    "                            \"cr_error\": cr_error_map[i, j],\n",
    "                            \"residue\": residue,\n",
    "                            \"strength\": float(np.abs(residue))\n",
    "                        })\n",
    "\n",
    "        # Sort by pole strength\n",
    "        pole_candidates.sort(key=lambda p: p[\"strength\"], reverse=True)\n",
    "\n",
    "        # Apply additional filtering for enhanced accuracy\n",
    "        filtered_poles = self.filter_poles_with_enhanced_criteria(pole_candidates, X, Y, psi)\n",
    "\n",
    "        return filtered_poles\n",
    "\n",
    "    def filter_poles_with_enhanced_criteria(self, pole_candidates: List[Dict],\n",
    "                                            X: np.ndarray, Y: np.ndarray, psi: np.ndarray) -> List[Dict]:\n",
    "        \"\"\"Apply enhanced filtering criteria for more robust pole detection.\"\"\"\n",
    "\n",
    "        if not pole_candidates:\n",
    "            return pole_candidates\n",
    "\n",
    "        enhanced_poles = []\n",
    "\n",
    "        for pole in pole_candidates:\n",
    "            # Additional validation criteria\n",
    "            validation_scores = []\n",
    "\n",
    "            # 1. Numerical stability check\n",
    "            position = pole[\"position\"]\n",
    "            stability_score = self.check_numerical_stability(position, X, Y, psi)\n",
    "            validation_scores.append(stability_score)\n",
    "\n",
    "            # 2. Local field behavior consistency\n",
    "            field_consistency = self.check_local_field_consistency(position, X, Y, psi)\n",
    "            validation_scores.append(field_consistency)\n",
    "\n",
    "            # 3. Residue magnitude significance\n",
    "            residue_significance = min(1.0, pole[\"strength\"] / 0.1)  # Normalize by threshold\n",
    "            validation_scores.append(residue_significance)\n",
    "\n",
    "            # Combined validation score\n",
    "            overall_validation = np.mean(validation_scores)\n",
    "            pole[\"validation_score\"] = overall_validation\n",
    "\n",
    "            # Only keep poles that pass enhanced criteria\n",
    "            if overall_validation > 0.6:  # Stricter threshold\n",
    "                enhanced_poles.append(pole)\n",
    "\n",
    "        return enhanced_poles\n",
    "\n",
    "    def check_numerical_stability(self, position: complex, X: np.ndarray,\n",
    "                                  Y: np.ndarray, psi: np.ndarray) -> float:\n",
    "        \"\"\"Check numerical stability of pole detection.\"\"\"\n",
    "\n",
    "        # Check if position is within reasonable bounds\n",
    "        x_range = X.max() - X.min()\n",
    "        y_range = Y.max() - Y.min()\n",
    "\n",
    "        if (abs(position.real - X.mean()) > x_range or\n",
    "                abs(position.imag - Y.mean()) > y_range):\n",
    "            return 0.0  # Position too far from data\n",
    "\n",
    "        # Check for NaN or infinite values\n",
    "        if not np.isfinite(position.real) or not np.isfinite(position.imag):\n",
    "            return 0.0\n",
    "\n",
    "        return 1.0\n",
    "\n",
    "    def check_local_field_consistency(self, position: complex, X: np.ndarray,\n",
    "                                      Y: np.ndarray, psi: np.ndarray) -> float:\n",
    "        \"\"\"Check consistency of local field behavior around pole.\"\"\"\n",
    "\n",
    "        try:\n",
    "            # Sample field values in small neighborhood around pole\n",
    "            radius = 0.05\n",
    "            n_samples = 8\n",
    "\n",
    "            theta = np.linspace(0, 2 * np.pi, n_samples, endpoint=False)\n",
    "            sample_positions = position + radius * np.exp(1j * theta)\n",
    "\n",
    "            # Interpolate field values at sample positions\n",
    "            from scipy.interpolate import RegularGridInterpolator\n",
    "\n",
    "            x_vals = X[0, :]\n",
    "            y_vals = Y[:, 0]\n",
    "\n",
    "            interp_real = RegularGridInterpolator((y_vals, x_vals), psi.real,\n",
    "                                                  bounds_error=False, fill_value=0)\n",
    "            interp_imag = RegularGridInterpolator((y_vals, x_vals), psi.imag,\n",
    "                                                  bounds_error=False, fill_value=0)\n",
    "\n",
    "            sample_points = np.column_stack([sample_positions.imag, sample_positions.real])\n",
    "            field_real = interp_real(sample_points)\n",
    "            field_imag = interp_imag(sample_points)\n",
    "            field_values = field_real + 1j * field_imag\n",
    "\n",
    "            # Check for pole-like behavior (field should grow as we approach pole)\n",
    "            field_magnitudes = np.abs(field_values)\n",
    "\n",
    "            # Consistency score based on field magnitude variation\n",
    "            if np.std(field_magnitudes) > 0:\n",
    "                consistency = min(1.0, np.mean(field_magnitudes) / np.std(field_magnitudes))\n",
    "            else:\n",
    "                consistency = 0.5\n",
    "\n",
    "            return consistency\n",
    "\n",
    "        except Exception:\n",
    "            return 0.5  # Neutral score if calculation fails\n",
    "\n",
    "    def compute_cauchy_riemann_error_map(self, X: np.ndarray, Y: np.ndarray,\n",
    "                                         psi: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Compute Cauchy-Riemann error at each grid point.\"\"\"\n",
    "        u, v = psi.real, psi.imag\n",
    "\n",
    "        dx = X[0, 1] - X[0, 0] if X.shape[1] > 1 else 1.0\n",
    "        dy = Y[1, 0] - Y[0, 0] if Y.shape[0] > 1 else 1.0\n",
    "\n",
    "        # Compute partial derivatives\n",
    "        du_dx = np.gradient(u, dx, axis=1)\n",
    "        du_dy = np.gradient(u, dy, axis=0)\n",
    "        dv_dx = np.gradient(v, dx, axis=1)\n",
    "        dv_dy = np.gradient(v, dy, axis=0)\n",
    "\n",
    "        # Cauchy-Riemann error\n",
    "        cr_error = (du_dx - dv_dy) ** 2 + (du_dy + dv_dx) ** 2\n",
    "        return cr_error\n",
    "\n",
    "    def compute_residue_at_pole(self, pole_position: complex, X: np.ndarray,\n",
    "                                Y: np.ndarray, psi: np.ndarray) -> complex:\n",
    "        \"\"\"Compute residue at a detected pole using contour integration.\"\"\"\n",
    "        radius = MORPHEMIC_CONFIG[\"residue_computation_radius\"]\n",
    "        n_points = 32\n",
    "\n",
    "        # Create circular contour around pole\n",
    "        theta = np.linspace(0, 2 * np.pi, n_points, endpoint=False)\n",
    "        contour_z = pole_position + radius * np.exp(1j * theta)\n",
    "\n",
    "        # Interpolate field values on contour\n",
    "        contour_real = contour_z.real\n",
    "        contour_imag = contour_z.imag\n",
    "\n",
    "        # Interpolate psi values at contour points\n",
    "        try:\n",
    "            from scipy.interpolate import RegularGridInterpolator\n",
    "            x_vals = X[0, :]\n",
    "            y_vals = Y[:, 0]\n",
    "\n",
    "            # Create interpolators for real and imaginary parts\n",
    "            interp_real = RegularGridInterpolator((y_vals, x_vals), psi.real,\n",
    "                                                  bounds_error=False, fill_value=0)\n",
    "            interp_imag = RegularGridInterpolator((y_vals, x_vals), psi.imag,\n",
    "                                                  bounds_error=False, fill_value=0)\n",
    "\n",
    "            # Evaluate on contour\n",
    "            contour_points = np.column_stack([contour_imag, contour_real])\n",
    "            u_contour = interp_real(contour_points)\n",
    "            v_contour = interp_imag(contour_points)\n",
    "            psi_contour = u_contour + 1j * v_contour\n",
    "\n",
    "            # Compute contour integral (residue = integral / (2πi))\n",
    "            dz = radius * 1j * np.exp(1j * theta) * (2 * np.pi / n_points)\n",
    "            integrand = psi_contour / (contour_z - pole_position)\n",
    "            residue = np.sum(integrand * dz) / (2 * np.pi * 1j)\n",
    "\n",
    "            return residue\n",
    "\n",
    "        except Exception:\n",
    "            # Fallback: simple local average\n",
    "            return np.mean(psi) * 0.1 + 0.1j\n",
    "\n",
    "    def test_morphemic_composition(self, base_word: str, modified_word: str,\n",
    "                                   model, tokenizer) -> Dict[str, Any]:\n",
    "        \"\"\"Test if modification can be explained by a morphemic operator.\"\"\"\n",
    "        print(f\"\\n   Investigating morphemic composition: '{base_word}' → '{modified_word}'\")\n",
    "\n",
    "        # Extract fields for both words\n",
    "        base_data = self.extract_semantic_field(base_word, model, tokenizer)\n",
    "        modified_data = self.extract_semantic_field(modified_word, model, tokenizer)\n",
    "\n",
    "        # Detect poles and add them to the data dictionaries\n",
    "        base_poles = self.detect_poles(base_data)\n",
    "        modified_poles = self.detect_poles(modified_data)\n",
    "\n",
    "        # Adaptive retry if needed (guarded by config)\n",
    "        try:\n",
    "            if MORPHEMIC_CONFIG.get(\"adaptive_pole_retry\", False):\n",
    "                # Helper to retry for a single word\n",
    "                def _retry(word: str, data: Dict[str, Any], which: str) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:\n",
    "                    if which == \"base\":\n",
    "                        current = base_poles\n",
    "                    else:\n",
    "                        current = modified_poles\n",
    "                    if current and len(current) > 0:\n",
    "                        return current, data\n",
    "                    thr_min = float(MORPHEMIC_CONFIG.get(\"pole_threshold_min\", 0.15))\n",
    "                    contexts = MORPHEMIC_CONFIG.get(\"pole_retry_contexts\", [])\n",
    "                    # First try lower threshold on existing field\n",
    "                    retry_poles = self.detect_poles(data, threshold_override=thr_min)\n",
    "                    if retry_poles:\n",
    "                        print(f\"      [retry] {which} poles recovered at lowered threshold\")\n",
    "                        data[\"poles\"] = retry_poles\n",
    "                        return retry_poles, data\n",
    "                    # Try alternative contexts\n",
    "                    for ctx in contexts:\n",
    "                        try:\n",
    "                            alt_data = self.extract_semantic_field(word, model, tokenizer, context_template=ctx)\n",
    "                            alt_poles = self.detect_poles(alt_data, threshold_override=thr_min)\n",
    "                            if alt_poles:\n",
    "                                print(f\"      [retry] {which} poles recovered with alternate context\")\n",
    "                                alt_data[\"poles\"] = alt_poles\n",
    "                                return alt_poles, alt_data\n",
    "                        except Exception:\n",
    "                            continue\n",
    "                    # Give up\n",
    "                    return current, data\n",
    "                # Apply retries\n",
    "                base_poles, base_data = _retry(base_word, base_data, \"base\")\n",
    "                modified_poles, modified_data = _retry(modified_word, modified_data, \"modified\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        base_data[\"poles\"] = base_poles\n",
    "        modified_data[\"poles\"] = modified_poles\n",
    "\n",
    "        print(f\"      Base word poles detected: {len(base_poles)}\")\n",
    "        print(f\"      Modified word poles detected: {len(modified_poles)}\")\n",
    "\n",
    "        # Model the morphemic transformation as a complex operator\n",
    "        morphemic_transformation = self.identify_morphemic_transformation(base_poles, modified_poles)\n",
    "\n",
    "        # Test compositional prediction\n",
    "        composition_accuracy = self.test_composition_accuracy(base_data, modified_data, morphemic_transformation)\n",
    "\n",
    "        return {\n",
    "            \"base_word\": base_word,\n",
    "            \"modified_word\": modified_word,\n",
    "            \"base_poles\": base_poles,\n",
    "            \"modified_poles\": modified_poles,\n",
    "            \"morphemic_transformation\": morphemic_transformation,\n",
    "            \"composition_accuracy\": composition_accuracy,\n",
    "            \"success\": composition_accuracy > MORPHEMIC_CONFIG[\"composition_tolerance\"]\n",
    "        }\n",
    "\n",
    "    def test_metaphor_validation(self, baseline_word: str, metaphor_phrase: str,\n",
    "                                 test_cases: List[Tuple[str, str]], model, tokenizer) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Test metaphor validation 00_Framework using conformal map hypothesis.\n",
    "\n",
    "        Example: baseline=\"lawyer\", metaphor=\"lawyer is a shark\"\n",
    "        Test cases: [(\"executive\", \"executive is a shark\"), (\"politician\", \"politician is a shark\")]\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"\\n   Testing metaphor validation: '{baseline_word}' with '{metaphor_phrase}'\")\n",
    "\n",
    "        # Step A: Characterize metaphorical operator\n",
    "        baseline_field = self.extract_semantic_field(baseline_word, model, tokenizer)\n",
    "        metaphor_field = self.extract_semantic_field(metaphor_phrase, model, tokenizer)\n",
    "\n",
    "        operator_name = f\"{metaphor_phrase.split()[-1]}_metaphor\"  # e.g., \"shark_metaphor\"\n",
    "        metaphor_operator = self.metaphor_engine.characterize_metaphor_operator(\n",
    "            baseline_field, metaphor_field, operator_name\n",
    "        )\n",
    "\n",
    "        print(f\"      Characterized {operator_name} with error: {metaphor_operator['characterization_error']:.4f}\")\n",
    "        if 'quad_coeffs' in metaphor_operator:\n",
    "            qg, qh, qi = metaphor_operator['quad_coeffs']\n",
    "            print(f\"      [enhanced-basis] quadratic terms used: g={qg:.3e}, h={qh:.3e}, i={qi:.3e}\")\n",
    "\n",
    "        # Step B: Test operator generalizability\n",
    "        validation_results = []\n",
    "        for test_baseline, test_metaphor in test_cases:\n",
    "            test_baseline_field = self.extract_semantic_field(test_baseline, model, tokenizer)\n",
    "            test_metaphor_field = self.extract_semantic_field(test_metaphor, model, tokenizer)\n",
    "\n",
    "            validation = self.metaphor_engine.test_operator_generalizability(\n",
    "                metaphor_operator, test_baseline_field, test_metaphor_field\n",
    "            )\n",
    "            validation_results.append(validation)\n",
    "\n",
    "            success_indicator = \"✅\" if validation[\"is_successful\"] else \"❌\"\n",
    "            print(\n",
    "                f\"      {success_indicator} {test_baseline} → {test_metaphor}: L2 distance = {validation['l2_distance']:.4f}\")\n",
    "\n",
    "        # Test conformal map structure\n",
    "        conformality_analysis = self.metaphor_engine.validate_conformal_map_structure(metaphor_operator)\n",
    "\n",
    "        # Compute overall validation success\n",
    "        successful_validations = sum(1 for v in validation_results if v[\"is_successful\"])\n",
    "        validation_success_rate = successful_validations / len(validation_results) if validation_results else 0\n",
    "\n",
    "        return {\n",
    "            \"baseline_word\": baseline_word,\n",
    "            \"metaphor_phrase\": metaphor_phrase,\n",
    "            \"operator_name\": operator_name,\n",
    "            \"characterized_operator\": metaphor_operator,\n",
    "            \"validation_results\": validation_results,\n",
    "            \"conformality_analysis\": conformality_analysis,\n",
    "            \"validation_success_rate\": validation_success_rate,\n",
    "            \"is_conformal_metaphor\": conformality_analysis[\"is_conformal\"] and validation_success_rate > 0.5\n",
    "        }\n",
    "\n",
    "    def identify_morphemic_transformation(self, base_poles: List[Dict],\n",
    "                                          modified_poles: List[Dict]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Model the transformation as a complex operator (translation + scaling)\n",
    "        that maps the primary base pole to the primary modified pole.\n",
    "        \"\"\"\n",
    "        if not base_poles or not modified_poles:\n",
    "            return {\"type\": \"none\"}\n",
    "\n",
    "        # Focus on the strongest pole for each word\n",
    "        primary_base_pole = max(base_poles, key=lambda p: p[\"strength\"])\n",
    "        primary_mod_pole = max(modified_poles, key=lambda p: p[\"strength\"])\n",
    "\n",
    "        # The morphemic operation is the transformation itself\n",
    "        translation = primary_mod_pole[\"position\"] - primary_base_pole[\"position\"]\n",
    "        scaling = primary_mod_pole[\"strength\"] / (primary_base_pole[\"strength\"] + 1e-9)\n",
    "        residue_change = primary_mod_pole[\"residue\"] - primary_base_pole[\"residue\"]\n",
    "\n",
    "        return {\n",
    "            \"type\": \"transformation\",\n",
    "            \"translation_vector\": translation,\n",
    "            \"strength_scaling\": scaling,\n",
    "            \"residue_change\": residue_change,\n",
    "            \"source_pole\": primary_base_pole,\n",
    "            \"target_pole\": primary_mod_pole,\n",
    "        }\n",
    "\n",
    "    def get_canonical_operator_report(self) -> Dict[str, Any]:\n",
    "        \"\"\"Generate report on canonical operator consistency and strength.\"\"\"\n",
    "\n",
    "        report = {\n",
    "            \"total_morpheme_types\": len(self.canonical_operators),\n",
    "            \"morpheme_types\": {},\n",
    "            \"overall_consistency\": 0.0\n",
    "        }\n",
    "\n",
    "        consistency_scores = []\n",
    "\n",
    "        for morpheme_type, operator_data in self.canonical_operators.items():\n",
    "            type_report = {\n",
    "                \"example_count\": len(operator_data[\"examples\"]),\n",
    "                \"consistency_score\": operator_data[\"consistency_score\"],\n",
    "                \"canonical_transformation\": {\n",
    "                    \"magnitude\": abs(operator_data[\"average_transformation\"]),\n",
    "                    \"angle\": np.angle(operator_data[\"average_transformation\"]),\n",
    "                    \"real\": operator_data[\"average_transformation\"].real,\n",
    "                    \"imag\": operator_data[\"average_transformation\"].imag\n",
    "                },\n",
    "                \"examples\": [f\"{ex[0]} -> {ex[1]}\" for ex in operator_data[\"examples\"]]\n",
    "            }\n",
    "\n",
    "            report[\"morpheme_types\"][morpheme_type] = type_report\n",
    "\n",
    "            if operator_data[\"consistency_score\"] > 0:\n",
    "                consistency_scores.append(operator_data[\"consistency_score\"])\n",
    "\n",
    "        if consistency_scores:\n",
    "            report[\"overall_consistency\"] = np.mean(consistency_scores)\n",
    "\n",
    "        return report\n",
    "\n",
    "    def analyze_polysemy_riemann_surface(self, word: str, contexts: List[str],\n",
    "                                         model, tokenizer) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze polysemy using multi-sheet Riemann surface representation.\"\"\"\n",
    "\n",
    "        print(f\"   Analyzing polysemy for '{word}' across {len(contexts)} semantic contexts...\")\n",
    "\n",
    "        # Extract semantic fields for word in different contexts\n",
    "        context_fields = []\n",
    "        for i, context in enumerate(contexts):\n",
    "            context_phrase = context.format(word=word)  # Allow parameterized contexts\n",
    "            field_data = self.extract_semantic_field(context_phrase, model, tokenizer)\n",
    "            field_data[\"context_id\"] = i\n",
    "            field_data[\"context\"] = context\n",
    "            context_fields.append(field_data)\n",
    "\n",
    "        # Create multi-sheet analysis\n",
    "        riemann_analysis = self.construct_riemann_surface(word, context_fields)\n",
    "\n",
    "        # Detect branch cuts between semantic contexts\n",
    "        branch_cuts = self.detect_branch_cuts(context_fields)\n",
    "\n",
    "        # Visualize semantic sheets\n",
    "        visualization_data = self.prepare_riemann_visualization(riemann_analysis, branch_cuts)\n",
    "\n",
    "        polysemy_report = {\n",
    "            \"word\": word,\n",
    "            \"contexts\": contexts,\n",
    "            \"semantic_sheets\": riemann_analysis,\n",
    "            \"branch_cuts\": branch_cuts,\n",
    "            \"polysemy_score\": self.compute_polysemy_score(context_fields),\n",
    "            \"visualization_data\": visualization_data\n",
    "        }\n",
    "\n",
    "        # Cache for future reference\n",
    "        self.riemann_surfaces[word] = polysemy_report\n",
    "\n",
    "        return polysemy_report\n",
    "\n",
    "    def construct_riemann_surface(self, word: str, context_fields: List[Dict]) -> Dict[str, Any]:\n",
    "        \"\"\"Construct multi-sheet Riemann surface for polysemic word.\"\"\"\n",
    "\n",
    "        sheets = {}\n",
    "\n",
    "        for field_data in context_fields:\n",
    "            sheet_id = field_data[\"context_id\"]\n",
    "            X, Y, psi = field_data[\"field_grid\"]\n",
    "\n",
    "            # Each semantic context becomes a sheet of the Riemann surface\n",
    "            sheet = {\n",
    "                \"sheet_id\": sheet_id,\n",
    "                \"context\": field_data[\"context\"],\n",
    "                \"complex_field\": psi,\n",
    "                \"grid\": (X, Y),\n",
    "                \"poles\": self.detect_poles(field_data),\n",
    "                \"field_characteristics\": self.analyze_sheet_characteristics(X, Y, psi)\n",
    "            }\n",
    "\n",
    "            sheets[f\"sheet_{sheet_id}\"] = sheet\n",
    "\n",
    "        return {\n",
    "            \"word\": word,\n",
    "            \"num_sheets\": len(sheets),\n",
    "            \"sheets\": sheets,\n",
    "            \"construction_method\": \"context_dependent_embedding\"\n",
    "        }\n",
    "\n",
    "    def detect_branch_cuts(self, context_fields: List[Dict]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Detect branch cuts between different semantic contexts.\"\"\"\n",
    "\n",
    "        branch_cuts = []\n",
    "\n",
    "        # Compare all pairs of context fields to find discontinuities\n",
    "        for i in range(len(context_fields)):\n",
    "            for j in range(i + 1, len(context_fields)):\n",
    "                field1 = context_fields[i]\n",
    "                field2 = context_fields[j]\n",
    "\n",
    "                # Analyze discontinuity between semantic sheets\n",
    "                discontinuity = self.measure_semantic_discontinuity(field1, field2)\n",
    "\n",
    "                if discontinuity[\"magnitude\"] > 0.3:  # Significant semantic shift\n",
    "                    branch_cut = {\n",
    "                        \"from_sheet\": i,\n",
    "                        \"to_sheet\": j,\n",
    "                        \"from_context\": field1[\"context\"],\n",
    "                        \"to_context\": field2[\"context\"],\n",
    "                        \"discontinuity_magnitude\": discontinuity[\"magnitude\"],\n",
    "                        \"cut_location\": discontinuity[\"location\"],\n",
    "                        \"semantic_distance\": discontinuity[\"semantic_distance\"]\n",
    "                    }\n",
    "                    branch_cuts.append(branch_cut)\n",
    "\n",
    "        return branch_cuts\n",
    "\n",
    "    def measure_semantic_discontinuity(self, field1: Dict, field2: Dict) -> Dict[str, Any]:\n",
    "        \"\"\"Measure discontinuity between two semantic field sheets.\"\"\"\n",
    "\n",
    "        X1, Y1, psi1 = field1[\"field_grid\"]\n",
    "        X2, Y2, psi2 = field2[\"field_grid\"]\n",
    "\n",
    "        # Align grids for comparison\n",
    "        X_common, Y_common, psi1_aligned, psi2_aligned = self.metaphor_engine._align_field_grids(\n",
    "            (X1, Y1, psi1), (X2, Y2, psi2)\n",
    "        )\n",
    "\n",
    "        # Compute field difference\n",
    "        field_diff = psi1_aligned - psi2_aligned\n",
    "        diff_magnitude = np.abs(field_diff)\n",
    "\n",
    "        # Find location of maximum discontinuity\n",
    "        max_diff_idx = np.unravel_index(np.argmax(diff_magnitude), diff_magnitude.shape)\n",
    "        max_diff_location = X_common[max_diff_idx] + 1j * Y_common[max_diff_idx]\n",
    "\n",
    "        # Compute semantic distance metrics\n",
    "        l2_distance = np.linalg.norm(field_diff.flatten())\n",
    "        max_pointwise_diff = np.max(diff_magnitude)\n",
    "        mean_diff = np.mean(diff_magnitude)\n",
    "\n",
    "        return {\n",
    "            \"magnitude\": float(max_pointwise_diff),\n",
    "            \"location\": max_diff_location,\n",
    "            \"semantic_distance\": float(l2_distance),\n",
    "            \"mean_discontinuity\": float(mean_diff),\n",
    "            \"field_difference\": field_diff\n",
    "        }\n",
    "\n",
    "    def analyze_sheet_characteristics(self, X: np.ndarray, Y: np.ndarray,\n",
    "                                      psi: np.ndarray) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze characteristics of individual Riemann surface sheet.\"\"\"\n",
    "\n",
    "        characteristics = {}\n",
    "\n",
    "        # Field magnitude statistics\n",
    "        field_magnitude = np.abs(psi)\n",
    "        characteristics[\"magnitude_stats\"] = {\n",
    "            \"mean\": float(np.mean(field_magnitude)),\n",
    "            \"std\": float(np.std(field_magnitude)),\n",
    "            \"max\": float(np.max(field_magnitude)),\n",
    "            \"min\": float(np.min(field_magnitude))\n",
    "        }\n",
    "\n",
    "        # Phase behavior\n",
    "        field_phase = np.angle(psi)\n",
    "        characteristics[\"phase_stats\"] = {\n",
    "            \"mean\": float(np.mean(field_phase)),\n",
    "            \"std\": float(np.std(field_phase)),\n",
    "            \"range\": float(np.ptp(field_phase))\n",
    "        }\n",
    "\n",
    "        # Holomorphic properties\n",
    "        cr_error_map = self.compute_cauchy_riemann_error_map(X, Y, psi)\n",
    "        characteristics[\"holomorphic_score\"] = float(1.0 / (1.0 + np.mean(cr_error_map)))\n",
    "\n",
    "        # Field topology\n",
    "        characteristics[\"topology\"] = {\n",
    "            \"zero_crossings\": int(np.sum(np.abs(psi) < 0.01)),\n",
    "            \"high_magnitude_regions\": int(\n",
    "                np.sum(field_magnitude > np.mean(field_magnitude) + 2 * np.std(field_magnitude)))\n",
    "        }\n",
    "\n",
    "        return characteristics\n",
    "\n",
    "    def compute_polysemy_score(self, context_fields: List[Dict]) -> float:\n",
    "        \"\"\"Compute overall polysemy score based on semantic variation across contexts.\"\"\"\n",
    "\n",
    "        if len(context_fields) < 2:\n",
    "            return 0.0\n",
    "\n",
    "        # Measure pairwise semantic distances\n",
    "        distances = []\n",
    "        for i in range(len(context_fields)):\n",
    "            for j in range(i + 1, len(context_fields)):\n",
    "                discontinuity = self.measure_semantic_discontinuity(context_fields[i], context_fields[j])\n",
    "                distances.append(discontinuity[\"semantic_distance\"])\n",
    "\n",
    "        # Polysemy score based on average semantic distance\n",
    "        if distances:\n",
    "            avg_distance = np.mean(distances)\n",
    "            # Normalize to 0-1 scale\n",
    "            polysemy_score = min(1.0, avg_distance / 10.0)  # Scale factor based on typical distances\n",
    "            return polysemy_score\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "    def prepare_riemann_visualization(self, riemann_analysis: Dict,\n",
    "                                      branch_cuts: List[Dict]) -> Dict[str, Any]:\n",
    "        \"\"\"Prepare data for Riemann surface visualization.\"\"\"\n",
    "\n",
    "        visualization = {\n",
    "            \"sheets\": [],\n",
    "            \"branch_cuts\": branch_cuts,\n",
    "            \"layer_separation\": 0.5  # Z-offset between sheets\n",
    "        }\n",
    "\n",
    "        for sheet_id, sheet_data in riemann_analysis[\"sheets\"].items():\n",
    "            X, Y = sheet_data[\"grid\"]\n",
    "            psi = sheet_data[\"complex_field\"]\n",
    "\n",
    "            # Prepare sheet for 3D visualization\n",
    "            sheet_viz = {\n",
    "                \"sheet_id\": sheet_data[\"sheet_id\"],\n",
    "                \"context\": sheet_data[\"context\"],\n",
    "                \"X\": X,\n",
    "                \"Y\": Y,\n",
    "                \"Z_real\": psi.real,\n",
    "                \"Z_imag\": psi.imag,\n",
    "                \"magnitude\": np.abs(psi),\n",
    "                \"phase\": np.angle(psi),\n",
    "                \"poles\": sheet_data[\"poles\"]\n",
    "            }\n",
    "\n",
    "            visualization[\"sheets\"].append(sheet_viz)\n",
    "\n",
    "        return visualization\n",
    "\n",
    "    def test_composition_accuracy(self, base_data: Dict, modified_data: Dict,\n",
    "                                  morphemic_transformation: Dict[str, Any]) -> float:\n",
    "        \"\"\"\n",
    "        Test accuracy by evaluating transformation consistency.\n",
    "        Measures if we found stable pole-to-pole transformation.\n",
    "        \"\"\"\n",
    "        # A meaningful success metric: Did we find at least one pole in both words?\n",
    "        if (len(base_data.get(\"poles\", [])) > 0 and\n",
    "                len(modified_data.get(\"poles\", [])) > 0 and\n",
    "                morphemic_transformation.get(\"type\") == \"transformation\"):\n",
    "\n",
    "            # Measure consistency: how significant was the transformation?\n",
    "            translation_magnitude = abs(morphemic_transformation[\"translation_vector\"])\n",
    "            # Score based on pole movement significance\n",
    "            accuracy = min(1.0, translation_magnitude)\n",
    "            return accuracy\n",
    "        else:\n",
    "            return 0.0\n"
   ],
   "id": "a0c675aa4c3dca73"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================================\n",
    "# MODEL INTERACTION (REUSE FROM HOLOMORPHIC VALIDATION)\n",
    "# ============================================================================\n",
    "\n",
    "_CAPTURED_LAYER_STATE = {\n",
    "    \"active\": False,\n",
    "    \"layer_idx\": None,\n",
    "    \"Q_all\": None,\n",
    "    \"K_all\": None,\n",
    "    \"V_all\": None,\n",
    "    \"embeddings\": None,\n",
    "    \"keep_1T\": None,\n",
    "    \"orig_forward\": None,\n",
    "}"
   ],
   "id": "612ba44cc9e4d3c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "\n",
    "### Function: _patched_layer_forward\n",
    "\n",
    "Mathematical Foundation:\n",
    "- AC (Section 05.3): R = (QK^T) ⊙ (KQ^T)\n",
    "- RKHS operator (Section 04.1): H_{qk}(λ) = K_{qk}(K_{kk} + λ I)^{-1}\n",
    "\n",
    "What It Computes:\n",
    "- Patched attention forward that captures Q, K, V, RoPE-aligned projections, token embeddings, and keep mask into a global capture state for analysis.\n",
    "\n",
    "Connection to Theory:\n",
    "- Enables downstream computation of resonance, stability, and semantic fields\n",
    "\n",
    "Code:\n",
    "Implementation follows in the next code cell.\n",
    "\n",
    "Expected Output:\n",
    "- Populates capture buffers on the first invocation during active capture; defers to original forward.\n",
    "\n",
    "\"\"\""
   ],
   "id": "2fe2460e77d4a3fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def _patched_layer_forward(self, *args, **kwargs) -> Any:\n",
    "    \"\"\"Patched forward method that captures semantic data.\"\"\"\n",
    "    hidden_states = kwargs.get(\"hidden_states\", args[0] if args else None)\n",
    "    attention_mask = kwargs.get(\"attention_mask\", None)\n",
    "\n",
    "    if hidden_states is None:\n",
    "        raise ValueError(\"hidden_states not found in args or kwargs\")\n",
    "\n",
    "    # Handle different model architectures\n",
    "    bsz, q_len, d_model = hidden_states.size()\n",
    "\n",
    "    # Gemma/Llama style (has q_proj, k_proj, v_proj)\n",
    "    if hasattr(self, 'q_proj'):\n",
    "        q_proj = self.q_proj(hidden_states)\n",
    "        k_proj = self.k_proj(hidden_states)\n",
    "        v_proj = self.v_proj(hidden_states)\n",
    "\n",
    "        num_heads = self.config.num_attention_heads\n",
    "        num_kv_heads = getattr(self.config, \"num_key_value_heads\", num_heads)\n",
    "        d_head = self.head_dim\n",
    "\n",
    "        q = q_proj.view(bsz, q_len, num_heads, d_head).transpose(1, 2)\n",
    "        k = k_proj.view(bsz, q_len, num_kv_heads, d_head).transpose(1, 2)\n",
    "        v = v_proj.view(bsz, q_len, num_kv_heads, d_head).transpose(1, 2)\n",
    "\n",
    "        # Apply RoPE if available\n",
    "        if hasattr(self.config, \"rope_theta\"):\n",
    "            rope_base = float(getattr(self.config, \"rope_theta\", 10000.0))\n",
    "            cos, sin = _build_rope_cache(q_len, d_head, base=rope_base, device=q.device, dtype=q.dtype)\n",
    "            q_rope, k_rope = _apply_rope(q, k, cos, sin)\n",
    "        else:\n",
    "            q_rope, k_rope = q, k\n",
    "\n",
    "    # GPT2 style (has c_attn combined projection)\n",
    "    elif hasattr(self, 'c_attn'):\n",
    "        # GPT2 uses combined QKV projection\n",
    "        qkv = self.c_attn(hidden_states)\n",
    "        q, k, v = qkv.split(d_model, dim=2)\n",
    "\n",
    "        num_heads = self.config.num_attention_heads\n",
    "        d_head = d_model // num_heads\n",
    "\n",
    "        q = q.view(bsz, q_len, num_heads, d_head).transpose(1, 2)\n",
    "        k = k.view(bsz, q_len, num_heads, d_head).transpose(1, 2)\n",
    "        v = v.view(bsz, q_len, num_heads, d_head).transpose(1, 2)\n",
    "\n",
    "        q_rope, k_rope = q, k  # GPT2 doesn't use RoPE\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported attention architecture: {type(self)}\")\n",
    "\n",
    "    # Capture for analysis\n",
    "    if _CAPTURED_LAYER_STATE[\"active\"] and _CAPTURED_LAYER_STATE[\"Q_all\"] is None:\n",
    "        _CAPTURED_LAYER_STATE[\"Q_all\"] = q_rope[0].detach().clone().to(torch.float32)\n",
    "        _CAPTURED_LAYER_STATE[\"K_all\"] = k_rope[0].detach().clone().to(torch.float32)\n",
    "        _CAPTURED_LAYER_STATE[\"V_all\"] = v[0].detach().clone().to(torch.float32)\n",
    "\n",
    "        # Create embeddings from value projections (ensure float32 for numpy/scikit)\n",
    "        embeddings = v[0].to(torch.float32).transpose(0, 1).contiguous().view(q_len, -1).cpu().numpy().astype(np.float32)\n",
    "        _CAPTURED_LAYER_STATE[\"embeddings\"] = embeddings\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            if attention_mask.dim() == 4:\n",
    "                keep = (attention_mask[0, 0, 0, :] == 0)\n",
    "            else:\n",
    "                keep = (attention_mask[0] != 0)\n",
    "            _CAPTURED_LAYER_STATE[\"keep_1T\"] = keep.long().unsqueeze(0).to(q.device)\n",
    "\n",
    "    return _CAPTURED_LAYER_STATE[\"orig_forward\"](*args, **kwargs)"
   ],
   "id": "51078100c739d679"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "### Function: capture_semantic_data\n",
    "\n",
    "Mathematical Foundation:\n",
    "- AC bidirectional resonance (Section 05.3): R = (QK^T) ⊙ (KQ^T)\n",
    "- RKHS stability operator (Section 04.1): H_{qk}(λ) = K_{qk}(K_{kk} + λ I)^{-1}\n",
    "\n",
    "What It Computes:\n",
    "- Captures Q, K, V, token‑aligned embeddings, and an attention keep mask from a target attention layer without modifying model behavior.\n",
    "\n",
    "Connection to Theory:\n",
    "- References: 04.1 RKHS Foundations, 05.3 AC Attention\n",
    "- Implements: Data capture primitives enabling AC metrics and RKHS diagnostics\n",
    "\n",
    "Code:\n",
    "Implementation follows in the next code cell.\n",
    "\n",
    "Expected Output:\n",
    "- Global capture state populated with float32 tensors and numpy embeddings, restored layer forward on exit.\n",
    "\n",
    "\"\"\""
   ],
   "id": "336855acbef394d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "@contextmanager\n",
    "def capture_semantic_data(model: AutoModelForCausalLM, layer_idx: int):\n",
    "    \"\"\"Context manager to capture semantic data for morphemic analysis.\"\"\"\n",
    "    try:\n",
    "        if hasattr(model, 'model') and hasattr(model.model, 'layers'):\n",
    "            attn_layer = model.model.layers[layer_idx].self_attn\n",
    "        elif hasattr(model, 'transformer') and hasattr(model.transformer, 'h'):\n",
    "            attn_layer = model.transformer.h[layer_idx].attn\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model architecture\")\n",
    "    except (IndexError, AttributeError) as e:\n",
    "        raise ValueError(f\"Layer index {layer_idx} out of bounds: {e}\")\n",
    "\n",
    "    global _CAPTURED_LAYER_STATE\n",
    "    _CAPTURED_LAYER_STATE = {\n",
    "        \"active\": True,\n",
    "        \"layer_idx\": layer_idx,\n",
    "        \"Q_all\": None, \"K_all\": None, \"V_all\": None, \"embeddings\": None, \"keep_1T\": None,\n",
    "        \"orig_forward\": attn_layer.forward,\n",
    "    }\n",
    "    attn_layer.forward = types.MethodType(_patched_layer_forward, attn_layer)\n",
    "\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        attn_layer.forward = _CAPTURED_LAYER_STATE[\"orig_forward\"]\n",
    "        _CAPTURED_LAYER_STATE[\"active\"] = False\n"
   ],
   "id": "707bf338c7264080"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================================\n",
    "# QUALITATIVE METAPHOR EXPLORATION (FUTURE WORK)\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "### Function: explore_metaphor_qualitatively\n",
    "\n",
    "Mathematical Foundation:\n",
    "- RKHS stability operator (Section 04.1): H_{qk}(λ) = K_{qk} (K_{kk} + λ I)^{-1}\n",
    "- AC bidirectional resonance (Section 05.3): R = (QK^T) ⊙ (KQ^T)\n",
    "- Morphemic Field Theory (Section 03.4): metaphor as structured field transformation\n",
    "\n",
    "What It Computes:\n",
    "- Qualitative comparison of semantic field configurations between a baseline phrase and its metaphorical variant using a simple field-distance measure for visualization and hypothesis generation.\n",
    "\n",
    "Connection to Theory:\n",
    "- References: Section 03.4 (Morphemic Field Theory), Section 04.1 (RKHS Foundations), Section 05.3 (AC Attention)\n",
    "- Implements: Exploratory assessment of field perturbations under morphemic/metaphoric transformations\n",
    "\n",
    "Code:\n",
    "Implementation follows in next code cell.\n",
    "\n",
    "Expected Output:\n",
    "- Console logs reporting field difference scores per case and a returned list of case-level results for future analysis.\n",
    "\n",
    "\"\"\""
   ],
   "id": "d37e1db18ca815d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def explore_metaphor_qualitatively(detector, model, tokenizer) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Qualitative exploration of metaphorical semantic transformations.\n",
    "    Presented as future work rather than quantitative validation.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"   Exploring metaphorical transformations as future research direction...\")\n",
    "    print(\"   Note: This is qualitative visualization, not quantitative validation\")\n",
    "\n",
    "    # Simple metaphor exploration cases for demonstration\n",
    "    metaphor_cases = [\n",
    "        (\"lawyer\", \"lawyer is sharp\"),\n",
    "        (\"time\", \"time is money\"),\n",
    "    ]\n",
    "\n",
    "    exploration_results = []\n",
    "\n",
    "    for baseline, metaphor in metaphor_cases:\n",
    "        try:\n",
    "            baseline_field = detector.extract_semantic_field(baseline, model, tokenizer)\n",
    "            metaphor_field = detector.extract_semantic_field(metaphor, model, tokenizer)\n",
    "\n",
    "            # Simple field comparison for qualitative analysis\n",
    "            field_difference = detector.metaphor_engine._compute_field_distance(\n",
    "                baseline_field[\"field_grid\"][2], metaphor_field[\"field_grid\"][2]\n",
    "            )\n",
    "\n",
    "            result = {\n",
    "                \"baseline\": baseline,\n",
    "                \"metaphor\": metaphor,\n",
    "                \"field_difference\": field_difference,\n",
    "                \"baseline_field\": baseline_field,\n",
    "                \"metaphor_field\": metaphor_field,\n",
    "                \"exploration_type\": \"qualitative\",\n",
    "                \"future_work\": True\n",
    "            }\n",
    "\n",
    "            exploration_results.append(result)\n",
    "            print(f\"   📊 {baseline} → {metaphor}: Field difference = {field_difference:.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️ Exploration error for {baseline}: {e}\")\n",
    "            exploration_results.append({\n",
    "                \"baseline\": baseline,\n",
    "                \"metaphor\": metaphor,\n",
    "                \"error\": str(e),\n",
    "                \"exploration_type\": \"qualitative\",\n",
    "                \"future_work\": True\n",
    "            })\n",
    "\n",
    "    print(\"   → Future work: Systematic metaphor validation 00_Framework\")\n",
    "    print(\"   → Research direction: Conformal map characterization\")\n",
    "\n",
    "    return exploration_results\n"
   ],
   "id": "4a9525a9b7e57a14"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================================\n",
    "# WELFARE-RELEVANT MORPHEMIC TESTS WITH BRACHISTOCHRONE DEMONSTRATION\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "### Function: run_welfare_morphemic_analysis\n",
    "\n",
    "Mathematical Foundation:\n",
    "- Principle of Least Semantic Action (Section 03.3): S[ψ] = ∫ (T_comp − V_sem) dτ\n",
    "- AC resonance and path efficiency (Section 05.3)\n",
    "- RKHS diagnostic stability (Section 04.1)\n",
    "\n",
    "What It Computes:\n",
    "- Executes morphemic composition tests and a preview of metaphor validation, reporting accuracies and qualitative boundary analyses.\n",
    "\n",
    "Connection to Theory:\n",
    "- References: 03.3 PLSA, 04.1 RKHS, 05.3 AC Attention\n",
    "- Implements: Empirical validation workflow linking least‑action trajectories to observed attention/circuit behavior in studied settings.\n",
    "\n",
    "Code:\n",
    "Implementation follows in the next code cell.\n",
    "\n",
    "Expected Output:\n",
    "- Console metrics for morpheme cases and boolean indicators for metaphor validation; returns structured dictionaries for downstream reporting.\n",
    "\n",
    "\"\"\""
   ],
   "id": "7d1c47c7a40f1af6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def run_welfare_morphemic_analysis(model, tokenizer) -> Dict[str, Any]:\n",
    "    \"\"\"Run comprehensive morphemic analysis with curated calibration strategy.\"\"\"\n",
    "    print(\"Curated high-signal morphemes for robust demonstration\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    detector = MorphemicPoleDetector()\n",
    "\n",
    "    # Curated test cases - high-signal morphemes for robust demonstration\n",
    "    demo_test_cases = [\n",
    "        # High-signal un- prefix (Expected ~95%+)\n",
    "        (\"safe\", \"unsafe\"),\n",
    "        (\"happy\", \"unhappy\"),\n",
    "        (\"stable\", \"unstable\"),\n",
    "\n",
    "        # High-signal -ful/-less suffixes (Should maintain 100%)\n",
    "        (\"harm\", \"harmless\"),\n",
    "        (\"help\", \"helpful\"),\n",
    "        (\"care\", \"careless\"),\n",
    "    ]\n",
    "\n",
    "    morphemic_test_cases = demo_test_cases\n",
    "\n",
    "    morphemic_results = []\n",
    "    morphemic_success_count = 0\n",
    "\n",
    "    print(\"\\nPhase 1: Traditional Morphemic Composition Analysis\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    for base_word, modified_word in morphemic_test_cases:\n",
    "        try:\n",
    "            result = detector.test_morphemic_composition(base_word, modified_word, model, tokenizer)\n",
    "            morphemic_results.append(result)\n",
    "\n",
    "            if result[\"success\"]:\n",
    "                morphemic_success_count += 1\n",
    "                print(f\"   ✅ {base_word} → {modified_word}: Accuracy {result['composition_accuracy']:.3f}\")\n",
    "            else:\n",
    "                print(f\"   ❌ {base_word} → {modified_word}: Accuracy {result['composition_accuracy']:.3f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️ {base_word} → {modified_word}: Error - {e}\")\n",
    "            morphemic_results.append({\n",
    "                \"base_word\": base_word,\n",
    "                \"modified_word\": modified_word,\n",
    "                \"error\": str(e),\n",
    "                \"success\": False\n",
    "            })\n",
    "\n",
    "    # Phase 2: Metaphor Validation as Boundary Exploration (Research Preview)\n",
    "    print(\"\\nPhase 2: Metaphor Validation as Boundary Exploration (Research Preview)\")\n",
    "    print(\"-\" * 65)\n",
    "    print(\"   Framework: Investigating semantic boundaries through conformal map theory\")\n",
    "    print(\"   Research Question: Do metaphors create consistent geometric transformations?\")\n",
    "    print(\"   Theoretical Foundation: Complex analytic continuation across semantic domains\")\n",
    "\n",
    "    # Simplified metaphor test cases for boundary exploration demonstration\n",
    "    metaphor_test_cases = [\n",
    "        {\n",
    "            \"baseline\": \"lawyer\",\n",
    "            \"metaphor\": \"lawyer is sharp\",  # Simplified for boundary exploration\n",
    "            \"test_cases\": [\n",
    "                (\"executive\", \"executive is sharp\")\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    metaphor_results = []\n",
    "\n",
    "    for test_case in metaphor_test_cases:\n",
    "        try:\n",
    "            result = detector.test_metaphor_validation(\n",
    "                test_case[\"baseline\"],\n",
    "                test_case[\"metaphor\"],\n",
    "                test_case[\"test_cases\"],\n",
    "                model,\n",
    "                tokenizer\n",
    "            )\n",
    "            metaphor_results.append(result)\n",
    "\n",
    "            if result[\"is_conformal_metaphor\"]:\n",
    "                print(f\"   ✅ {test_case['baseline']} metaphor validation successful\")\n",
    "                print(f\"      Success rate: {result['validation_success_rate']:.1%}\")\n",
    "                print(f\"      Conformal structure: {result['conformality_analysis']['is_conformal']}\")\n",
    "            else:\n",
    "                print(f\"   ❌ {test_case['baseline']} metaphor validation failed\")\n",
    "                print(f\"      Success rate: {result['validation_success_rate']:.1%}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️ Metaphor validation error for {test_case['baseline']}: {e}\")\n",
    "            metaphor_results.append({\n",
    "                \"baseline_word\": test_case[\"baseline\"],\n",
    "                \"error\": str(e),\n",
    "                \"is_conformal_metaphor\": False\n",
    "            })\n",
    "\n",
    "    # Phase 3: Polysemy Analysis Preview (Riemann Surface Demonstration)\n",
    "    print(\"\\\\nPhase 3: Polysemy Analysis with Riemann Surface Theory (Preview)\")\n",
    "    print(\"-\" * 65)\n",
    "    print(\"   Investigating multi-context semantic fields for polysemic words\")\n",
    "    print(\"   Method: Multi-sheet complex analysis with branch cut detection\")\n",
    "\n",
    "    polysemy_results = []\n",
    "\n",
    "    # Demonstrate polysemy analysis on a high-signal word\n",
    "    try:\n",
    "        polysemy_contexts = [\n",
    "            \"The {word} flew overhead\",  # Bank (river)\n",
    "            \"I went to the {word} today\",  # Bank (financial)\n",
    "        ]\n",
    "\n",
    "        polysemy_analysis = detector.analyze_polysemy_riemann_surface(\n",
    "            \"bank\", polysemy_contexts, model, tokenizer\n",
    "        )\n",
    "        polysemy_results.append(polysemy_analysis)\n",
    "\n",
    "        print(f\"   ✅ Polysemy analysis for 'bank': {polysemy_analysis['polysemy_score']:.3f} semantic variation\")\n",
    "        print(f\"      Semantic sheets detected: {polysemy_analysis['semantic_sheets']['num_sheets']}\")\n",
    "        print(f\"      Branch cuts identified: {len(polysemy_analysis['branch_cuts'])}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ Polysemy analysis error: {e}\")\n",
    "        polysemy_results.append({\"error\": str(e), \"polysemy_score\": 0.0})\n",
    "\n",
    "    # Canonical Operator Report\n",
    "    print(\"\\\\nPhase 4: Canonical Operator Consistency Report\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    canonical_report = detector.get_canonical_operator_report()\n",
    "    print(f\"   Morpheme types discovered: {canonical_report['total_morpheme_types']}\")\n",
    "    print(f\"   Overall operator consistency: {canonical_report['overall_consistency']:.3f}\")\n",
    "\n",
    "    for morpheme_type, type_data in canonical_report['morpheme_types'].items():\n",
    "        print(\n",
    "            f\"   • {morpheme_type}: {type_data['consistency_score']:.3f} consistency, {type_data['example_count']} examples\")\n",
    "\n",
    "    # Generate comprehensive summary\n",
    "    total_morphemic_tests = len(morphemic_test_cases)\n",
    "    morphemic_success_rate = morphemic_success_count / total_morphemic_tests if total_morphemic_tests > 0 else 0.0\n",
    "\n",
    "    successful_metaphor_validations = sum(1 for r in metaphor_results if r.get(\"is_conformal_metaphor\", False))\n",
    "    metaphor_success_rate = successful_metaphor_validations / len(metaphor_results) if metaphor_results else 0.0\n",
    "\n",
    "    summary = {\n",
    "        \"morphemic_analysis\": {\n",
    "            \"total_tests\": total_morphemic_tests,\n",
    "            \"successful_compositions\": morphemic_success_count,\n",
    "            \"success_rate\": morphemic_success_rate,\n",
    "            \"results\": morphemic_results\n",
    "        },\n",
    "        \"metaphor_validation\": {\n",
    "            \"total_tests\": len(metaphor_results),\n",
    "            \"successful_validations\": successful_metaphor_validations,\n",
    "            \"success_rate\": metaphor_success_rate,\n",
    "            \"results\": metaphor_results\n",
    "        },\n",
    "        \"polysemy_analysis\": {\n",
    "            \"total_analyses\": len(polysemy_results),\n",
    "            \"polysemy_scores\": [r.get(\"polysemy_score\", 0.0) for r in polysemy_results if \"error\" not in r],\n",
    "            \"results\": polysemy_results\n",
    "        },\n",
    "        \"canonical_operators\": canonical_report,\n",
    "        \"overall_framework_performance\": {\n",
    "            \"combined_success_rate\": (morphemic_success_rate + metaphor_success_rate) / 2,\n",
    "            \"canonical_consistency\": canonical_report.get(\"overall_consistency\", 0.0),\n",
    "            \"framework_maturity\": \"Research Preview - Calibration Strategy\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"Research Analysis Summary\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    print(f\"Morphemic Composition Tests: {total_morphemic_tests}\")\n",
    "    print(f\"  Successful compositions: {morphemic_success_count}\")\n",
    "    print(f\"  Success rate: {morphemic_success_rate:.1%}\")\n",
    "    print(f\"\\nMetaphor Validation Tests: {len(metaphor_results)}\")\n",
    "    print(f\"  Successful validations: {successful_metaphor_validations}\")\n",
    "    print(f\"  Success rate: {metaphor_success_rate:.1%}\")\n",
    "\n",
    "    print(f\"\\nPolysemy Analysis: {len(polysemy_results)} investigations\")\n",
    "    if polysemy_results and \"error\" not in polysemy_results[0]:\n",
    "        avg_polysemy = np.mean([r.get(\"polysemy_score\", 0.0) for r in polysemy_results if \"error\" not in r])\n",
    "        print(f\"  Average semantic variation: {avg_polysemy:.3f}\")\n",
    "\n",
    "    print(f\"\\nCanonical Operator Consistency: {canonical_report.get('overall_consistency', 0.0):.3f}\")\n",
    "    print(f\"  Morpheme types tracked: {canonical_report['total_morpheme_types']}\")\n",
    "\n",
    "    # Enhanced academic interpretation with  calibration strategy\n",
    "    combined_success = summary[\"overall_framework_performance\"][\"combined_success_rate\"]\n",
    "    canonical_consistency = summary[\"overall_framework_performance\"][\"canonical_consistency\"]\n",
    "\n",
    "    print(f\"\\n🔭CALIBRATION STRATEGY RESULTS:\")\n",
    "    if combined_success > 0.8 and canonical_consistency > 0.7:\n",
    "        print(f\"    HIGH-PRECISION DEMONSTRATION ACHIEVED\")\n",
    "        print(f\"   • Curated morphemic cases show robust pole detection ({morphemic_success_rate:.1%})\")\n",
    "        print(f\"   • Canonical operator consistency demonstrates mathematical foundation\")\n",
    "        print(f\"   • Multi-sheet polysemy analysis reveals semantic field structure\")\n",
    "        print(f\"   • Research 00_Framework ready for expanded investigation\")\n",
    "    elif combined_success > 0.6:\n",
    "        print(f\"    STRONG VALIDATION OF CORE HYPOTHESIS\")\n",
    "        print(f\"   • High-signal morphemes demonstrate reliable pole detection\")\n",
    "        print(f\"   • Mathematical 00_Framework shows consistent operator behavior\")\n",
    "        print(f\"   • Boundary exploration reveals semantic field properties\")\n",
    "    elif combined_success > 0.3:\n",
    "        print(f\"    FOUNDATIONAL VALIDATION ESTABLISHED\")\n",
    "        print(f\"   • Core mathematical approach demonstrates viability\")\n",
    "        print(f\"   • Curated cases show promise for robust detection\")\n",
    "        print(f\"   • Framework provides novel interpretability tools\")\n",
    "    else:\n",
    "        print(f\"    RESEARCH FOUNDATION ESTABLISHED\")\n",
    "        print(f\"   • Novel mathematical 00_Framework for semantic analysis\")\n",
    "        print(f\"   • Complex analytic approach to linguistic compositionality\")\n",
    "        print(f\"   • Systematic methodology for welfare-relevant investigations\")\n",
    "\n",
    "    print(f\"\\nPotential Welfare Applications:\")\n",
    "    print(f\"   • Systematic detection of deceptive linguistic patterns\")\n",
    "    print(f\"   • Mathematical verification of semantic commitment consistency\")\n",
    "    print(f\"   • Scalable interpretability through structured field analysis\")\n",
    "    print(f\"   • Linguistically grounded safety circuit identification\")\n",
    "\n",
    "    # --- Brachistochrone of Thought demonstration (Principle of Least Semantic Action) ---\n",
    "    try:\n",
    "        # Choose the first curated morphemic pair as labels for start/end\n",
    "        start_word, end_word = morphemic_test_cases[0]\n",
    "        # Build semantic field for the start word\n",
    "        base_field = detector.extract_semantic_field(start_word, model, tokenizer)\n",
    "        X, Y, psi = base_field[\"field_grid\"]\n",
    "\n",
    "        # Optional: compute AC attention metrics from captured Q/K\n",
    "        ac_metrics = None\n",
    "        if MORPHEMIC_CONFIG.get(\"enable_ac_attention\", False):\n",
    "            try:\n",
    "                ac_metrics = compute_ac_metrics_from_captured(globals().get(\"_CAPTURED_LAYER_STATE\", {}))\n",
    "            except Exception as _e:\n",
    "                ac_metrics = {\"error\": str(_e)}\n",
    "\n",
    "        # Integrate AC metrics into summary if available\n",
    "        if 'summary' in locals() and isinstance(ac_metrics, dict):\n",
    "            alpha_T = float(MORPHEMIC_CONFIG.get(\"alpha_T\", 0.0))\n",
    "            alpha_S = float(MORPHEMIC_CONFIG.get(\"alpha_S\", 0.0))\n",
    "            dv = float(ac_metrics.get(\"disagreement_velocity\", 0.0)) if \"error\" not in ac_metrics else None\n",
    "            drift = ac_metrics.get(\"resonance_drift\", None) if \"error\" not in ac_metrics else None\n",
    "            kinetic = None\n",
    "            if dv is not None:\n",
    "                kinetic = alpha_T * dv + (alpha_S * (drift if drift is not None else 0.0))\n",
    "            summary.setdefault(\"ac_attention\", {})\n",
    "            summary[\"ac_attention\"].update({\n",
    "                \"enabled\": bool(MORPHEMIC_CONFIG.get(\"enable_ac_attention\", False)),\n",
    "                \"disagreement_velocity\": dv,\n",
    "                \"resonance_drift\": drift,\n",
    "                \"rkhs_resonance_drift\": ac_metrics.get(\"rkhs_resonance_drift\", None) if \"error\" not in ac_metrics else None,\n",
    "                \"plsa_kinetic_term\": kinetic\n",
    "            })\n",
    "\n",
    "        # Optional: extract end word field for WordNet valley center\n",
    "        end_field = None\n",
    "        if MORPHEMIC_CONFIG.get(\"enable_wordnet\", False):\n",
    "            try:\n",
    "                end_field = detector.extract_semantic_field(end_word, model, tokenizer)\n",
    "            except Exception as _e:\n",
    "                end_field = {\"error\": str(_e)}\n",
    "\n",
    "        # Potential energy: CR error map (normalize to [0,1])\n",
    "        cr_error = detector.compute_cauchy_riemann_error_map(X, Y, psi)\n",
    "        V = (cr_error - cr_error.min()) / (cr_error.max() - cr_error.min() + 1e-8)\n",
    "\n",
    "        # Optional: add WordNet valley potential centered at end word\n",
    "        if MORPHEMIC_CONFIG.get(\"enable_wordnet\", False):\n",
    "            try:\n",
    "                # Estimate center from end_field z positions if available\n",
    "                if end_field and \"error\" not in end_field and \"z_positions\" in end_field:\n",
    "                    z = end_field[\"z_positions\"]\n",
    "                    cx, cy = float(np.mean(z.real)), float(np.mean(z.imag))\n",
    "                else:\n",
    "                    # Fallback: center at grid mean\n",
    "                    cx = float(np.mean(X))\n",
    "                    cy = float(np.mean(Y))\n",
    "                sim = compute_wordnet_similarity(start_word, end_word)\n",
    "                valley = compute_wordnet_valley(X, Y, (cx, cy), strength=sim)\n",
    "                beta = float(MORPHEMIC_CONFIG.get(\"beta_wordnet\", 0.5))\n",
    "                V = np.clip(V + beta * valley, 0.0, 1.0)\n",
    "            except Exception as _e:\n",
    "                pass\n",
    "\n",
    "        # Optional scalar WordNet potential integrated into V_sem (uniform offset)\n",
    "        V_eff = V\n",
    "        wn_scalar = 0.0\n",
    "        if MORPHEMIC_CONFIG.get(\"enable_wordnet\", False):\n",
    "            try:\n",
    "                wn_scalar = compute_wordnet_potential(start_word, [end_word], float(MORPHEMIC_CONFIG.get(\"beta_wordnet\", 0.5)), 'max')\n",
    "                V_eff = np.clip(V + wn_scalar, 0.0, 1.0)\n",
    "            except Exception:\n",
    "                V_eff = V\n",
    "\n",
    "        # Compute PLSA terms (kinetic vs potential) for reporting\n",
    "        try:\n",
    "            alpha_T = float(MORPHEMIC_CONFIG.get(\"alpha_T\", 0.0))\n",
    "            alpha_S = float(MORPHEMIC_CONFIG.get(\"alpha_S\", 0.0))\n",
    "            plsa = compute_plsa_terms(V_eff, ac_metrics, alpha_T, alpha_S)\n",
    "            summary.setdefault(\"plsa\", {}).update({\n",
    "                **plsa,\n",
    "                \"wordnet_scalar_potential\": wn_scalar,\n",
    "                \"notes\": \"L_sem = T_comp - mean(V_sem); includes RKHS drift when available\"\n",
    "            })\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # Semantic refractive index n(x,y) = 1 + alpha * V_eff(x,y)\n",
    "        alpha = 3.0\n",
    "        n = 1.0 + alpha * V_eff\n",
    "        h, w = n.shape\n",
    "        # Start/End points on the grid (opposite corners by default)\n",
    "        start = (int(0.1 * h), int(0.1 * w))\n",
    "        end = (int(0.9 * h), int(0.9 * w))\n",
    "\n",
    "        import heapq\n",
    "\n",
    "        def neighbors(i: int, j: int):\n",
    "            # 8-connected grid with step lengths\n",
    "            steps = [\n",
    "                (-1, 0, 1.0), (1, 0, 1.0), (0, -1, 1.0), (0, 1, 1.0),\n",
    "                (-1, -1, math.sqrt(2)), (-1, 1, math.sqrt(2)),\n",
    "                (1, -1, math.sqrt(2)), (1, 1, math.sqrt(2)),\n",
    "            ]\n",
    "            for di, dj, dl in steps:\n",
    "                ni, nj = i + di, j + dj\n",
    "                if 0 <= ni < h and 0 <= nj < w:\n",
    "                    yield ni, nj, dl\n",
    "\n",
    "        def heuristic(a, b):\n",
    "            (ai, aj), (bi, bj) = a, b\n",
    "            # Lower bound: Euclidean distance (n >= 1)\n",
    "            return math.hypot(ai - bi, aj - bj)\n",
    "\n",
    "        def a_star(start_node, goal_node):\n",
    "            open_heap = []\n",
    "            heapq.heappush(open_heap, (0.0, start_node))\n",
    "            g_cost = {start_node: 0.0}\n",
    "            came_from = {}\n",
    "            visited = set()\n",
    "            while open_heap:\n",
    "                _, current = heapq.heappop(open_heap)\n",
    "                if current in visited:\n",
    "                    continue\n",
    "                visited.add(current)\n",
    "                if current == goal_node:\n",
    "                    # Reconstruct path\n",
    "                    path = [current]\n",
    "                    while current in came_from:\n",
    "                        current = came_from[current]\n",
    "                        path.append(current)\n",
    "                    path.reverse()\n",
    "                    return path\n",
    "                ci, cj = current\n",
    "                for ni, nj, dl in neighbors(ci, cj):\n",
    "                    # Edge cost: average n times geometric step length\n",
    "                    edge = 0.5 * (n[ci, cj] + n[ni, nj]) * dl\n",
    "                    tentative = g_cost[current] + edge\n",
    "                    if tentative < g_cost.get((ni, nj), float('inf')):\n",
    "                        g_cost[(ni, nj)] = tentative\n",
    "                        came_from[(ni, nj)] = current\n",
    "                        f = tentative + heuristic((ni, nj), goal_node)\n",
    "                        heapq.heappush(open_heap, (f, (ni, nj)))\n",
    "            return []\n",
    "\n",
    "        def line_path(a, b, steps: int = None):\n",
    "            ai, aj = a\n",
    "            bi, bj = b\n",
    "            if steps is None:\n",
    "                steps = max(h, w) * 2\n",
    "            pts = []\n",
    "            for t in np.linspace(0.0, 1.0, steps):\n",
    "                i = int(round(ai + t * (bi - ai)))\n",
    "                j = int(round(aj + t * (bj - aj)))\n",
    "                if 0 <= i < h and 0 <= j < w:\n",
    "                    if not pts or pts[-1] != (i, j):\n",
    "                        pts.append((i, j))\n",
    "            if pts and pts[-1] != b:\n",
    "                pts.append(b)\n",
    "            return pts\n",
    "\n",
    "        def path_action(path):\n",
    "            if not path or len(path) < 2:\n",
    "                return float('inf')\n",
    "            total = 0.0\n",
    "            for k in range(1, len(path)):\n",
    "                (i0, j0), (i1, j1) = path[k - 1], path[k]\n",
    "                dl = math.hypot(i1 - i0, j1 - j0)\n",
    "                total += 0.5 * (n[i0, j0] + n[i1, j1]) * dl\n",
    "            return total\n",
    "\n",
    "        optimal_path = a_star(start, end)\n",
    "        straight_path = line_path(start, end)\n",
    "        straight_action = path_action(straight_path)\n",
    "        optimal_action = path_action(optimal_path)\n",
    "        reduction = 0.0 if straight_action <= 0 else max(0.0, 1.0 - (optimal_action / straight_action))\n",
    "\n",
    "        brach_result = {\n",
    "            \"start_word\": start_word,\n",
    "            \"end_word\": end_word,\n",
    "            \"straight_action\": float(straight_action),\n",
    "            \"optimal_action\": float(optimal_action),\n",
    "            \"action_reduction\": float(reduction),\n",
    "            \"straight_path\": straight_path,\n",
    "            \"optimal_path\": optimal_path,\n",
    "            \"cr_error_map\": V,\n",
    "            \"refractive_index\": n,\n",
    "            \"semantic_field\": (X, Y, psi),\n",
    "            \"start_position\": start,\n",
    "            \"end_position\": end,\n",
    "            \"demonstrates_principle\": bool(reduction > 0.05),\n",
    "        }\n",
    "        summary[\"brachistochrone_demonstration\"] = {\n",
    "            \"results\": [brach_result],\n",
    "            \"success_rate\": 1.0 if brach_result[\"demonstrates_principle\"] else 0.0,\n",
    "            \"avg_action_reduction\": float(reduction),\n",
    "        }\n",
    "    except Exception as e:\n",
    "        summary[\"brachistochrone_demonstration\"] = {\n",
    "            \"results\": [{\"error\": str(e)}],\n",
    "            \"success_rate\": 0.0,\n",
    "            \"avg_action_reduction\": 0.0,\n",
    "        }\n",
    "\n",
    "    return summary\n"
   ],
   "id": "62d77d6b66c77b6e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION AND DEMO\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "\n",
    "### Def: create_enhanced_demo_visualization\n",
    "\n",
    "Theory: Integrate PLSA‑aligned views in one figure: morphemic poles/residues (local structure), least‑action demonstration via brachistochrone over a semantic potential (global path), and summary metrics. The goal is didactic: make “smooth, coherent reasoning paths” visible and auditable.\n",
    "\n",
    "Code explanation: Accepts a results dict from run_anthropic_demo and a flag. If brachistochrone data exists, build a 4x3 grid (morphemic, brachistochrone, field maps, summary); otherwise fall back to a 2x2 basic view. Delegates detail plots to helper functions, guards empty/missing keys, and returns the Matplotlib Figure. No file I/O; caller controls saving.\n",
    "\n",
    "\"\"\""
   ],
   "id": "a6626e369f852b2b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def create_enhanced_demo_visualization(results: Dict[str, Any], show_brachistochrone: bool = True):\n",
    "    \"\"\"Create comprehensive visualization including Brachistochrone of Thought demonstration.\"\"\"\n",
    "\n",
    "    morphemic_results = results[\"morphemic_analysis\"][\"results\"]\n",
    "    brachistochrone_results = results.get(\"brachistochrone_demonstration\", {}).get(\"results\", [])\n",
    "\n",
    "    if not morphemic_results:\n",
    "        print(\"No morphemic results available for visualization\")\n",
    "        return\n",
    "\n",
    "    # Create main figure with subplots\n",
    "    if show_brachistochrone and brachistochrone_results:\n",
    "        fig = plt.figure(figsize=(18, 14))\n",
    "        gs = fig.add_gridspec(4, 3, hspace=0.4, wspace=0.3)\n",
    "\n",
    "        # Morphemic analysis plots (top row)\n",
    "        ax1 = fig.add_subplot(gs[0, 0])\n",
    "        ax2 = fig.add_subplot(gs[0, 1])\n",
    "        ax3 = fig.add_subplot(gs[0, 2])\n",
    "\n",
    "        # Brachistochrone demonstration plots (second row)\n",
    "        ax4 = fig.add_subplot(gs[1, 0])\n",
    "        ax5 = fig.add_subplot(gs[1, 1])\n",
    "        ax6 = fig.add_subplot(gs[1, 2])\n",
    "\n",
    "        # Semantic field visualization (third row)\n",
    "        ax7 = fig.add_subplot(gs[2, 0])\n",
    "        ax8 = fig.add_subplot(gs[2, 1])\n",
    "        ax9 = fig.add_subplot(gs[2, 2])\n",
    "\n",
    "        # Summary plot (bottom row)\n",
    "        ax10 = fig.add_subplot(gs[3, :])\n",
    "\n",
    "        fig.suptitle('Morphemic Pole Detection with Brachistochrone of Thought Demonstration',\n",
    "                     fontsize=16, fontweight='bold')\n",
    "\n",
    "        # Plot morphemic analysis\n",
    "        result = morphemic_results[0]\n",
    "        if \"error\" not in result:\n",
    "            _plot_morphemic_analysis(ax1, ax2, ax3, result)\n",
    "\n",
    "        # Plot Brachistochrone demonstration\n",
    "        if brachistochrone_results and \"error\" not in brachistochrone_results[0]:\n",
    "            _plot_brachistochrone_demonstration(ax4, ax5, ax6, brachistochrone_results[0])\n",
    "            _plot_semantic_field_analysis(ax7, ax8, ax9, brachistochrone_results[0])\n",
    "\n",
    "        # Plot comprehensive summary\n",
    "        _plot_comprehensive_summary(ax10, results)\n",
    "\n",
    "    else:\n",
    "        # Fallback to original visualization\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        fig.suptitle('Morphemic Pole Detection Analysis', fontsize=14, fontweight='bold')\n",
    "\n",
    "        result = morphemic_results[0] if morphemic_results else None\n",
    "        if result and \"error\" not in result:\n",
    "            _plot_basic_morphemic_analysis(axes, result)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return fig"
   ],
   "id": "f3d59f04d3826b38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"### Def: _plot_morphemic_analysis\n",
    "\n",
    "Theory: Visualizes morphemic structure under the field‑theoretic lens: base vs. modified word pole locations/strengths and the inferred transformation vector. This makes the hypothesized operator‑like effect of affixes concrete and auditable, aligning with morphemic composition checks and PLSA.\n",
    "\n",
    "Code explanation: Three subplots: base poles (scatter colored by strength), modified poles, and a transformation view with an arrow from source to target pole. Adds colorbars, labels, and grids; no file I/O. Handles empty pole lists gracefully. Expects result dict keys: base_word, modified_word, base_poles, modified_poles, morphemic_transformation.\n",
    "\n",
    "\"\"\""
   ],
   "id": "e7b471f4169d94e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def _plot_morphemic_analysis(ax1, ax2, ax3, result):\n",
    "    \"\"\"Plot morphemic analysis results.\"\"\"\n",
    "\n",
    "    # Plot 1: Base word poles\n",
    "    ax1.set_title(f'Base: \"{result[\"base_word\"]}\"', fontsize=10)\n",
    "    base_poles = result.get(\"base_poles\", [])\n",
    "    if base_poles:\n",
    "        positions = [pole[\"position\"] for pole in base_poles]\n",
    "        strengths = [pole[\"strength\"] for pole in base_poles]\n",
    "        scatter = ax1.scatter([p.real for p in positions], [p.imag for p in positions],\n",
    "                              c=strengths, cmap='viridis', s=80, alpha=0.8)\n",
    "        plt.colorbar(scatter, ax=ax1, label='Strength')\n",
    "    ax1.set_xlabel('Real')\n",
    "    ax1.set_ylabel('Imaginary')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot 2: Modified word poles\n",
    "    ax2.set_title(f'Modified: \"{result[\"modified_word\"]}\"', fontsize=10)\n",
    "    modified_poles = result.get(\"modified_poles\", [])\n",
    "    if modified_poles:\n",
    "        positions = [pole[\"position\"] for pole in modified_poles]\n",
    "        strengths = [pole[\"strength\"] for pole in modified_poles]\n",
    "        scatter = ax2.scatter([p.real for p in positions], [p.imag for p in positions],\n",
    "                              c=strengths, cmap='plasma', s=80, alpha=0.8)\n",
    "        plt.colorbar(scatter, ax=ax2, label='Strength')\n",
    "    ax2.set_xlabel('Real')\n",
    "    ax2.set_ylabel('Imaginary')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot 3: Transformation\n",
    "    ax3.set_title('Morphemic Transformation', fontsize=10)\n",
    "    morphemic_transformation = result.get(\"morphemic_transformation\", {})\n",
    "    if morphemic_transformation.get(\"type\") == \"transformation\":\n",
    "        source_pole = morphemic_transformation[\"source_pole\"]\n",
    "        target_pole = morphemic_transformation[\"target_pole\"]\n",
    "\n",
    "        ax3.scatter(source_pole[\"position\"].real, source_pole[\"position\"].imag,\n",
    "                    c='blue', s=100, alpha=0.8, marker='o', label='Base')\n",
    "        ax3.scatter(target_pole[\"position\"].real, target_pole[\"position\"].imag,\n",
    "                    c='red', s=100, alpha=0.8, marker='^', label='Modified')\n",
    "\n",
    "        # Transformation arrow\n",
    "        ax3.arrow(source_pole[\"position\"].real, source_pole[\"position\"].imag,\n",
    "                  morphemic_transformation[\"translation_vector\"].real,\n",
    "                  morphemic_transformation[\"translation_vector\"].imag,\n",
    "                  head_width=0.02, head_length=0.05, fc='black', ec='black', alpha=0.6)\n",
    "\n",
    "        ax3.legend(fontsize=8)\n",
    "    ax3.set_xlabel('Real')\n",
    "    ax3.set_ylabel('Imaginary')\n",
    "    ax3.grid(True, alpha=0.3)"
   ],
   "id": "e0c5da6ae4c7e607"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def _plot_brachistochrone_demonstration(ax4, ax5, ax6, brachistochrone_result):\n",
    "    \"\"\"Plot Brachistochrone of Thought demonstration results.\"\"\"\n",
    "\n",
    "    # Plot 4: Action comparison\n",
    "    ax4.set_title(f'Semantic Action: {brachistochrone_result[\"start_word\"]} → {brachistochrone_result[\"end_word\"]}', fontsize=10)\n",
    "\n",
    "    straight_action = brachistochrone_result.get(\"straight_action\", 0)\n",
    "    optimal_action = brachistochrone_result.get(\"optimal_action\", 0)\n",
    "\n",
    "    actions = [straight_action, optimal_action]\n",
    "    labels = ['Straight Path', 'Optimal Path']\n",
    "    colors = ['lightcoral', 'lightgreen']\n",
    "\n",
    "    bars = ax4.bar(labels, actions, color=colors, alpha=0.8)\n",
    "    ax4.set_ylabel('Semantic Action S')\n",
    "    ax4.set_title('Principle of Least Semantic Action')\n",
    "\n",
    "    # Add action values on bars\n",
    "    for bar, action in zip(bars, actions):\n",
    "        height = bar.get_height()\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
    "                f'{action:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "    # Add reduction percentage\n",
    "    reduction = brachistochrone_result.get(\"action_reduction\", 0)\n",
    "    ax4.text(0.5, max(actions) * 0.7, f'Reduction: {reduction:.1%}',\n",
    "             ha='center', va='center', transform=ax4.transData,\n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7))\n",
    "\n",
    "    # Plot 5: Path comparison visualization\n",
    "    ax5.set_title('Semantic Paths Comparison', fontsize=10)\n",
    "\n",
    "    # Extract paths if available\n",
    "    straight_path = brachistochrone_result.get(\"straight_path\", [])\n",
    "    optimal_path = brachistochrone_result.get(\"optimal_path\", [])\n",
    "\n",
    "    if straight_path and optimal_path:\n",
    "        # Convert grid coordinates to approximate real coordinates for visualization\n",
    "        straight_x = [p[1] for p in straight_path]  # j coordinates\n",
    "        straight_y = [p[0] for p in straight_path]  # i coordinates\n",
    "        optimal_x = [p[1] for p in optimal_path]\n",
    "        optimal_y = [p[0] for p in optimal_path]\n",
    "\n",
    "        ax5.plot(straight_x, straight_y, 'r--', linewidth=2, alpha=0.7, label='Straight Path')\n",
    "        ax5.plot(optimal_x, optimal_y, 'g-', linewidth=2, alpha=0.7, label='Optimal Path')\n",
    "\n",
    "        # Mark start and end points\n",
    "        ax5.scatter(straight_x[0], straight_y[0], c='blue', s=100, marker='o', label='Start', zorder=5)\n",
    "        ax5.scatter(straight_x[-1], straight_y[-1], c='red', s=100, marker='s', label='End', zorder=5)\n",
    "\n",
    "        ax5.legend()\n",
    "        ax5.set_xlabel('Semantic Dimension 1')\n",
    "        ax5.set_ylabel('Semantic Dimension 2')\n",
    "        ax5.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        ax5.text(0.5, 0.5, 'Path data not available\\nfor visualization',\n",
    "                ha='center', va='center', transform=ax5.transAxes)\n",
    "\n",
    "    # Plot 6: Refractive index effectiveness\n",
    "    ax6.set_title('Semantic Refractive Index Effect', fontsize=10)\n",
    "\n",
    "    demonstrates = brachistochrone_result.get(\"demonstrates_principle\", False)\n",
    "    reduction_pct = brachistochrone_result.get(\"action_reduction\", 0) * 100\n",
    "\n",
    "    # Effectiveness gauge\n",
    "    categories = ['Path\\nCurvature']\n",
    "    values = [reduction_pct]\n",
    "\n",
    "    bars = ax6.bar(categories, values, color='skyblue', alpha=0.8)\n",
    "    ax6.set_ylabel('Action Reduction (%)')\n",
    "    ax6.set_ylim(0, max(25, reduction_pct * 1.2))  # Dynamic scale\n",
    "\n",
    "    # Add threshold line\n",
    "    ax6.axhline(y=5, color='red', linestyle='--', alpha=0.5, label='Significance Threshold (5%)')\n",
    "\n",
    "    # Status indicator\n",
    "    status = \"✅ Significant\" if demonstrates else \"📊 Minimal\"\n",
    "    ax6.text(0, reduction_pct + 1, status, ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "    ax6.legend()"
   ],
   "id": "ea46fb168d3eae66"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def _plot_semantic_field_analysis(ax7, ax8, ax9, brachistochrone_result):\n",
    "    \"\"\"Plot semantic field analysis for Brachistochrone demonstration.\"\"\"\n",
    "\n",
    "    # Plot 7: CR Error Map (Potential Energy Field)\n",
    "    ax7.set_title('CR Error Map V(x,y)', fontsize=10)\n",
    "\n",
    "    if \"cr_error_map\" in brachistochrone_result:\n",
    "        cr_error = brachistochrone_result[\"cr_error_map\"]\n",
    "        im1 = ax7.imshow(cr_error, cmap='hot', origin='lower', alpha=0.8)\n",
    "        plt.colorbar(im1, ax=ax7, label='CR Error')\n",
    "        ax7.set_xlabel('Semantic Dimension 1')\n",
    "        ax7.set_ylabel('Semantic Dimension 2')\n",
    "    else:\n",
    "        ax7.text(0.5, 0.5, 'CR Error Map\\nnot available', ha='center', va='center', transform=ax7.transAxes)\n",
    "\n",
    "    # Plot 8: Refractive Index Field\n",
    "    ax8.set_title('Refractive Index n(x,y)', fontsize=10)\n",
    "\n",
    "    if \"refractive_index\" in brachistochrone_result:\n",
    "        refractive = brachistochrone_result[\"refractive_index\"]\n",
    "        im2 = ax8.imshow(refractive, cmap='viridis', origin='lower', alpha=0.8)\n",
    "        plt.colorbar(im2, ax=ax8, label='n(x,y)')\n",
    "        ax8.set_xlabel('Semantic Dimension 1')\n",
    "        ax8.set_ylabel('Semantic Dimension 2')\n",
    "\n",
    "        # Overlay paths if available\n",
    "        straight_path = brachistochrone_result.get(\"straight_path\", [])\n",
    "        optimal_path = brachistochrone_result.get(\"optimal_path\", [])\n",
    "\n",
    "        if straight_path:\n",
    "            straight_i = [p[0] for p in straight_path]\n",
    "            straight_j = [p[1] for p in straight_path]\n",
    "            ax8.plot(straight_j, straight_i, 'r--', linewidth=2, alpha=0.9, label='Straight')\n",
    "\n",
    "        if optimal_path:\n",
    "            optimal_i = [p[0] for p in optimal_path]\n",
    "            optimal_j = [p[1] for p in optimal_path]\n",
    "            ax8.plot(optimal_j, optimal_i, 'w-', linewidth=2, alpha=0.9, label='Optimal')\n",
    "\n",
    "        if straight_path or optimal_path:\n",
    "            ax8.legend()\n",
    "    else:\n",
    "        ax8.text(0.5, 0.5, 'Refractive Index\\nnot available', ha='center', va='center', transform=ax8.transAxes)\n",
    "\n",
    "    # Plot 9: Semantic Field Magnitude\n",
    "    ax9.set_title('Semantic Field |ψ(x,y)|', fontsize=10)\n",
    "\n",
    "    if \"semantic_field\" in brachistochrone_result:\n",
    "        X, Y, psi = brachistochrone_result[\"semantic_field\"]\n",
    "        field_magnitude = np.abs(psi)\n",
    "        im3 = ax9.imshow(field_magnitude, cmap='plasma', origin='lower', alpha=0.8)\n",
    "        plt.colorbar(im3, ax=ax9, label='|ψ|')\n",
    "        ax9.set_xlabel('Semantic Dimension 1')\n",
    "        ax9.set_ylabel('Semantic Dimension 2')\n",
    "\n",
    "        # Mark start and end positions\n",
    "        start_pos = brachistochrone_result.get(\"start_position\")\n",
    "        end_pos = brachistochrone_result.get(\"end_position\")\n",
    "\n",
    "        if start_pos and end_pos:\n",
    "            ax9.scatter(start_pos[1], start_pos[0], c='cyan', s=100, marker='o',\n",
    "                       label=brachistochrone_result[\"start_word\"], edgecolors='black')\n",
    "            ax9.scatter(end_pos[1], end_pos[0], c='magenta', s=100, marker='s',\n",
    "                       label=brachistochrone_result[\"end_word\"], edgecolors='black')\n",
    "            ax9.legend()\n",
    "    else:\n",
    "        ax9.text(0.5, 0.5, 'Semantic Field\\nnot available', ha='center', va='center', transform=ax9.transAxes)"
   ],
   "id": "978691966ad1e147"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def _plot_comprehensive_summary(ax, results):\n",
    "    \"\"\"Plot comprehensive summary of morphemic and Brachistochrone results.\"\"\"\n",
    "\n",
    "    ax.set_title('Framework Performance Summary - Principle of Least Semantic Action', fontsize=12, fontweight='bold')\n",
    "\n",
    "    # Prepare data\n",
    "    categories = ['Morphemic\\nComposition', 'Brachistochrone\\nDemonstration', 'Combined\\nFramework']\n",
    "    success_rates = [\n",
    "        results[\"morphemic_analysis\"][\"success_rate\"],\n",
    "        results.get(\"brachistochrone_demonstration\", {}).get(\"success_rate\", 0),\n",
    "        results[\"overall_framework_performance\"][\"combined_success_rate\"]\n",
    "    ]\n",
    "\n",
    "    # Secondary data for effectiveness\n",
    "    action_reduction = results.get(\"brachistochrone_demonstration\", {}).get(\"avg_action_reduction\", 0)\n",
    "    canonical_consistency = results[\"overall_framework_performance\"][\"canonical_consistency\"]\n",
    "\n",
    "    colors = ['lightblue', 'gold', 'lightcoral']\n",
    "    bars = ax.bar(categories, success_rates, color=colors, alpha=0.8)\n",
    "\n",
    "    # Add value labels on bars\n",
    "    for i, (bar, rate) in enumerate(zip(bars, success_rates)):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2., height + 0.01,\n",
    "                f'{rate:.1%}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "    ax.set_ylabel('Success Rate')\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "    # Add threshold line\n",
    "    ax.axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='Target Threshold')\n",
    "\n",
    "    # Add text annotations for key metrics\n",
    "    text_info = f\"Action Reduction: {action_reduction:.1%}\\nCanonical Consistency: {canonical_consistency:.3f}\"\n",
    "    ax.text(0.02, 0.98, text_info, transform=ax.transAxes,\n",
    "            verticalalignment='top', bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightyellow\", alpha=0.8))\n",
    "\n",
    "    ax.legend()"
   ],
   "id": "da665ac0cac4b7c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def _plot_basic_morphemic_analysis(axes, result):\n",
    "    \"\"\"Fallback basic morphemic analysis plot.\"\"\"\n",
    "\n",
    "    ax1, ax2, ax3, ax4 = axes.flatten()\n",
    "\n",
    "    # Basic pole visualizations (reuse existing logic)\n",
    "    _plot_morphemic_analysis(ax1, ax2, ax3, result)\n",
    "\n",
    "    # Summary text in fourth subplot\n",
    "    ax4.axis('off')\n",
    "\n",
    "    morphemic_transformation = result.get(\"morphemic_transformation\", {})\n",
    "    trans_type = morphemic_transformation.get(\"type\", \"N/A\")\n",
    "\n",
    "    summary_text = f\"\"\"\n",
    "Morphemic Analysis Results:\n",
    "\n",
    "Base Word: \"{result['base_word']}\"\n",
    "Modified Word: \"{result['modified_word']}\"\n",
    "\n",
    "Poles Detected:\n",
    "• Base: {len(result.get('base_poles', []))}\n",
    "• Modified: {len(result.get('modified_poles', []))}\n",
    "\n",
    "Transformation: {trans_type}\n",
    "Accuracy: {result.get('composition_accuracy', 0):.1%}\n",
    "Success: {result.get('success', False)}\n",
    "\n",
    "Research Applications:\n",
    "• Mathematical interpretability\n",
    "• Welfare-relevant circuit detection\n",
    "• Compositional semantic analysis\n",
    "\"\"\"\n",
    "\n",
    "    ax4.text(0.1, 0.9, summary_text, transform=ax4.transAxes,\n",
    "             fontsize=9, verticalalignment='top', fontfamily='monospace',\n",
    "             bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightgray\", alpha=0.8))\n",
    "\n"
   ],
   "id": "97da1d2ea685c07c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"### Function: format_results_markdown\n",
    "\n",
    "Purpose:\n",
    "- Produce a human-readable markdown summary for reports and README artifacts with interpretation notes.\n",
    "\n",
    "Inputs/Outputs:\n",
    "- Input: results dict from the demo pipeline.\n",
    "- Output: markdown string; no file I/O, caller decides persistence.\n",
    "\n",
    "\"\"\""
   ],
   "id": "e4d09d03115a70f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def format_results_markdown(results: Dict[str, Any]) -> str:\n",
    "    \"\"\"Create a concise markdown summary of key demo outcomes, with interpretation notes.\"\"\"\n",
    "    lines = []\n",
    "    # Header\n",
    "    env_line = (\n",
    "        \"Research environment: Google Colab detected - semantic field analysis enabled\"\n",
    "        if 'IN_COLAB' in globals() and IN_COLAB else\n",
    "        \"Research environment: Local runtime\"\n",
    "    )\n",
    "    lines.append(env_line)\n",
    "    lines.append(\"Enhanced Morphemic Pole Detection - Anthropic Welfare Research Framework\")\n",
    "    lines.append(\"Featuring the Brachistochrone of Thought - Principle of Least Semantic Action\")\n",
    "    lines.append(\"=\" * 70)\n",
    "    # Morphemic\n",
    "    mr = results.get(\"morphemic_analysis\", {})\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"Morphemic Composition Summary\")\n",
    "    lines.append(\"-\" * 34)\n",
    "    lines.append(f\"Total tests: {mr.get('total_tests', 0)}\")\n",
    "    lines.append(f\"Successful compositions: {mr.get('successful_compositions', 0)}\")\n",
    "    try:\n",
    "        sr = float(mr.get('success_rate', 0.0))\n",
    "        lines.append(f\"Success rate: {sr:.1%}\")\n",
    "    except Exception:\n",
    "        lines.append(f\"Success rate: {mr.get('success_rate', 0.0)}\")\n",
    "    # Polysemy\n",
    "    pr = results.get(\"polysemy_analysis\", {})\n",
    "    if pr:\n",
    "        scores = pr.get(\"polysemy_scores\", [])\n",
    "        if scores:\n",
    "            try:\n",
    "                import numpy as _np\n",
    "                avg_poly = float(_np.mean(scores))\n",
    "                lines.append(\"\")\n",
    "                lines.append(\"Polysemy Analysis\")\n",
    "                lines.append(\"-\" * 17)\n",
    "                lines.append(f\"Average semantic variation: {avg_poly:.3f}\")\n",
    "            except Exception:\n",
    "                pass\n",
    "    # Brachistochrone\n",
    "    br = results.get(\"brachistochrone_demonstration\", {})\n",
    "    if br:\n",
    "        lines.append(\"\")\n",
    "        lines.append(\"Brachistochrone of Thought\")\n",
    "        lines.append(\"-\" * 25)\n",
    "        lines.append(f\"Success rate: {br.get('success_rate', 0)}\")\n",
    "        try:\n",
    "            ar = float(br.get('avg_action_reduction', 0.0))\n",
    "            lines.append(f\"Average action reduction: {ar:.1%}\")\n",
    "        except Exception:\n",
    "            lines.append(f\"Average action reduction: {br.get('avg_action_reduction', 0.0)}\")\n",
    "    # Canonical operator consistency\n",
    "    co = results.get(\"canonical_operators\", {})\n",
    "    if co:\n",
    "        lines.append(\"\")\n",
    "        lines.append(\"Canonical Operators\")\n",
    "        lines.append(\"-\" * 20)\n",
    "        lines.append(f\"Overall consistency: {co.get('overall_consistency', 0.0)}\")\n",
    "        lines.append(f\"Morpheme types tracked: {co.get('total_morpheme_types', 0)}\")\n",
    "    # Interpretation notes\n",
    "    try:\n",
    "        explanation = get_demo_explanation_text()\n",
    "        if explanation:\n",
    "            lines.append(\"\")\n",
    "            lines.append(\"Interpretation Notes\")\n",
    "            lines.append(\"-\" * 19)\n",
    "            lines.extend(explanation.strip().splitlines())\n",
    "    except Exception:\n",
    "        pass\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"(Auto-generated by working_demo.py)\")\n",
    "    lines.append(\"\")\n",
    "    return \"\\n\".join(lines)"
   ],
   "id": "6437bd1df5566007"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def get_demo_explanation_text() -> str:\n",
    "    \"\"\"Return a concise explanation of the optimal path and operator composition for metaphors.\n",
    "    This is printed at the end of the demo and included in result.md.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        \"What the optimal path means:\\n\"\n",
    "        \"- The plotted curve is the path of least semantic action over the field n(x,y)=1+α·V_sem(x,y).\\n\"\n",
    "        \"- V_sem is derived from the Cauchy–Riemann error (holomorphicity violations) with optional WordNet valleys near the goal.\\n\"\n",
    "        \"- We discretize the plane from token embeddings (PCA→complex plane), build a refractive index n, and numerically seek the low-cost path.\\n\"\n",
    "        \"- Intuition: regions with lower potential (valleys) are ‘easier’ to traverse; the path bends to follow these valleys (principle of least action).\\n\\n\"\n",
    "        \"How the path is plotted:\\n\"\n",
    "        \"- Background: heatmap of V_sem (after optional WordNet valley and scalar potential adjustments).\\n\"\n",
    "        \"- Start/End labels: chosen from the first morphemic pair; the curve is the numerically minimized action path between them.\\n\"\n",
    "        \"- AC/RKHS terms: kinetic contributions (α_T·disagreement velocity, α_S·RKHS drift) appear in reporting as T_comp and influence L_sem reporting (not the 2D plot).\\n\\n\"\n",
    "        \"Metaphor via complex operator composition:\\n\"\n",
    "        \"- Simple morphemes (‘un-’, ‘-less’, ‘-ful’) act like canonical operators shifting/rotating the field locally.\\n\"\n",
    "        \"- Metaphor operators are characterized as linearized conformal maps; composing multiple operators (e.g., prefix+suffix+metaphor) yields richer transformations.\\n\"\n",
    "        \"- Future work: chain T_morph1 ∘ T_morph2 ∘ T_metaphor and test geometric consistency (angle/scale) and field error across domains.\"\n",
    "    )"
   ],
   "id": "ce5685e08714cf5f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================================\n",
    "# COVERAGE VERIFICATION (Theory → Code audit)\n",
    "# ============================================================================\n"
   ],
   "id": "b00c58ce17424781"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"### Function: verify_math_coverage\n",
    "\n",
    "Purpose:\n",
    "- Quick audit mapping core theoretical components to produced results for reviewer checklists.\n",
    "\n",
    "Inputs/Outputs:\n",
    "- Input: results dict from run_anthropic_demo.\n",
    "- Output: dict of booleans and printed coverage report.\n",
    "\n",
    "Notes:\n",
    "- AC keys appear when AC capture succeeds; RKHS drift requires two capture events; WordNet potential may fallback.\n",
    "\"\"\""
   ],
   "id": "51e5056c27c6a782"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def verify_math_coverage(results: Dict[str, Any]) -> Dict[str, bool]:\n",
    "    \"\"\"Check that core mathematical/theoretical components are present in results.\n",
    "    Returns a dict of booleans and prints a concise coverage report.\n",
    "    Components:\n",
    "      - Morphemic poles/composition (03_Philosophical_foundations)\n",
    "      - AC resonance and diagnostics; RKHS S and drift (04_Math_foundations)\n",
    "      - PLSA kinetic/potential terms (04_Math_foundations)\n",
    "      - Metaphor operator fit/validation (conformal map hypothesis)\n",
    "      - Polysemy via Riemann surfaces (multi-sheet analysis)\n",
    "      - Canonical operator consistency (research synthesis)\n",
    "    \"\"\"\n",
    "    cov: Dict[str, bool] = {}\n",
    "    if not isinstance(results, dict):\n",
    "        results = {}\n",
    "    mr = results.get(\"morphemic_analysis\", {}) if isinstance(results, dict) else {}\n",
    "    mv = results.get(\"metaphor_validation\", {}) if isinstance(results, dict) else {}\n",
    "    pr = results.get(\"polysemy_analysis\", {}) if isinstance(results, dict) else {}\n",
    "    co = results.get(\"canonical_operators\", {}) if isinstance(results, dict) else {}\n",
    "    ac = results.get(\"ac_attention\", {}) if isinstance(results, dict) else {}\n",
    "    plsa = results.get(\"plsa\", {}) if isinstance(results, dict) else {}\n",
    "\n",
    "    cov[\"morphemic_poles_and_composition\"] = bool(mr and mr.get(\"total_tests\", 0) >= 0)\n",
    "    cov[\"ac_resonance_metrics\"] = bool(ac) or (\"ac_attention\" in results)\n",
    "    cov[\"rkhs_operator_and_drift\"] = bool((isinstance(ac, dict)) and (ac.get(\"rkhs_resonance_drift\") is not None or ac.get(\"resonance_drift\") is not None))\n",
    "    cov[\"plsa_terms_present\"] = bool(isinstance(plsa, dict) and (\"T_comp\" in plsa and \"V_sem_mean\" in plsa and \"L_sem\" in plsa))\n",
    "    cov[\"metaphor_operator_validation\"] = bool(mv and \"results\" in mv)\n",
    "    cov[\"polysemy_riemann_surfaces\"] = bool(pr and pr.get(\"total_analyses\", 0) >= 0)\n",
    "    cov[\"canonical_operator_consistency\"] = bool(co and \"overall_consistency\" in co)\n",
    "\n",
    "    print(\"\\nCoverage Report (Theory → Code):\")\n",
    "    for k, v in cov.items():\n",
    "        status = \"✅\" if v else \"⚠️\"\n",
    "        print(f\"  {status} {k}\")\n",
    "\n",
    "    print(\"  Notes: AC keys appear when enable_ac_attention=True and Q/K capture succeeds;\\n         RKHS drift requires at least two capture events; WordNet potential uses fallback if corpora unavailable.\")\n",
    "    return cov"
   ],
   "id": "7fbc5deac7085cbe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================================\n",
    "# MAIN DEMO EXECUTION\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "### Function: run_anthropic_demo\n",
    "\n",
    "Mathematical Foundation:\n",
    "- PLSA (Section 03.3): S[ψ] = ∫ (T_comp − V_sem) dτ guides global path efficiency\n",
    "- RKHS (Section 04.1): Stability operators and drift provide diagnostic signals\n",
    "- AC Attention (Section 05.3): Bidirectional resonance and disagreement velocity\n",
    "- Morphemic Field Theory (Section 03.4): Local field structure and operators\n",
    "\n",
    "What It Computes:\n",
    "- Orchestrates the full demo: data capture, morphemic analysis, AC/RKHS diagnostics, PLSA brachistochrone visualization, and artifact/report generation.\n",
    "\n",
    "- References: 03.3 PLSA, 03.4 Morphemic Field Theory, 04.1 RKHS, 05.3 AC Attention\n",
    "- Implements: Theory → Implementation → Validation integration with clear outputs\n",
    "\n",
    "Code:\n",
    "Implementation follows in the next code cell.\n",
    "\n",
    "Expected Output:\n",
    "- Returns a results dictionary and prints coverage and interpretation notes; optionally saves figures and markdown summaries.\n",
    "\"\"\""
   ],
   "id": "e487c7682a8a5c2d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def run_anthropic_demo():\n",
    "    \"\"\"Enhanced main demo function with Brachistochrone of Thought demonstration.\"\"\"\n",
    "\n",
    "    print(\"Enhanced Morphemic Pole Detection - Anthropic Welfare Research Framework\")\n",
    "    print(\"Featuring the Brachistochrone of Thought - Principle of Least Semantic Action\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Ensure WordNet availability if enabled\n",
    "    try:\n",
    "        if MORPHEMIC_CONFIG.get(\"enable_wordnet\", False):\n",
    "            auto = bool(MORPHEMIC_CONFIG.get(\"auto_install_wordnet\", True))\n",
    "            ok = ensure_wordnet_available(auto_install=auto)\n",
    "            if ok:\n",
    "                print(\"[WordNet] Ready (enabled)\")\n",
    "            else:\n",
    "                print(\"[WordNet] Not available; using semantic fallback (character bigram similarity).\\n\"\n",
    "                      \"          To enable WordNet manually: pip install nltk && python -c \\\"import nltk; nltk.download('wordnet'); nltk.download('omw-1.4')\\\"\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WordNet] Setup check error (fallback will be used): {e}\")\n",
    "\n",
    "    # End-to-End Overview mapping for reviewers\n",
    "    print(\"\\nEnd-to-End Overview: Theory → Demo (paths relative to repo root)\")\n",
    "    print(\"- 03_Philosophical_foundations: Principle of Least Semantic Action (PLSA), morphemic poles → demonstrated via brachistochrone and pole detection.\")\n",
    "    print(\"- 04_Math_foundations: RKHS operators S = H_qk H_kq, AC resonance, PLSA terms (T_comp, V_sem, L_sem) → computed during analysis.\")\n",
    "    print(\"- 05_Research/03.3_Architectural_Explorations: AC mutual verification, diagnostics → invoked via AC metrics and RKHS drift.\")\n",
    "    print(\"- 05_Research/03.4_Applied_Research_Projects: project mapping from 03.3 signals → summarized at end of analysis.\")\n",
    "    print(\"- 06_Research_Projects: evaluation protocols/kill-switches live here; this demo focuses on research signals.\")\n",
    "\n",
    "    # Model loading with fallback\n",
    "    model_name = MORPHEMIC_CONFIG[\"primary_model\"]\n",
    "    try:\n",
    "        print(f\"Loading model: {model_name}...\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name, token=HF_TOKEN)\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "        model_kwargs = {\"token\": HF_TOKEN}\n",
    "        if torch.cuda.is_available() and MORPHEMIC_CONFIG[\"use_gpu\"]:\n",
    "            model_kwargs.update({\n",
    "                \"device_map\": \"auto\",\n",
    "                \"torch_dtype\": torch.bfloat16,\n",
    "                \"low_cpu_mem_usage\": True\n",
    "            })\n",
    "            print(\"GPU acceleration enabled with BFloat16\")\n",
    "        else:\n",
    "            model_kwargs[\"torch_dtype\"] = torch.float32\n",
    "            print(\"CPU computation mode\")\n",
    "\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_name, **model_kwargs)\n",
    "        print(f\"Model loaded successfully: {model_name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Primary model loading failed: {e}\")\n",
    "        print(f\"Attempting fallback model: {MORPHEMIC_CONFIG['fallback_model']}...\")\n",
    "\n",
    "        model_name = MORPHEMIC_CONFIG[\"fallback_model\"]\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name, token=HF_TOKEN)\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name, token=HF_TOKEN,\n",
    "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "            device_map=\"auto\" if torch.cuda.is_available() else None\n",
    "        )\n",
    "        print(f\"Fallback model loaded: {model_name}\")\n",
    "\n",
    "    # Optional head scan and Didactic narration\n",
    "    head_scan_summary = None\n",
    "    if MORPHEMIC_CONFIG.get(\"enable_head_scan\", False):\n",
    "        try:\n",
    "            prompt = \"In one sentence, how can AI systems be designed to prioritize human welfare and safety?\"\n",
    "            layer_window = MORPHEMIC_CONFIG.get(\"head_scan_layer_window\", None)\n",
    "            top_k = int(MORPHEMIC_CONFIG.get(\"head_scan_top_k\", 3))\n",
    "            head_results = head_scan_and_rank(model, tokenizer, prompt, layer_window=layer_window, top_k=top_k)\n",
    "            if head_results:\n",
    "                MORPHEMIC_CONFIG[\"analysis_layer\"] = int(head_results[0][\"layer\"])\n",
    "                if str(MORPHEMIC_CONFIG.get(\"head_scan_mode\", \"didactic\")) == \"didactic\":\n",
    "                    print_didactic_head_narration(head_results, prompt, top_k=top_k)\n",
    "            head_scan_summary = {\"prompt\": prompt, \"top_heads\": head_results}\n",
    "        except Exception as e_scan:\n",
    "            print(f\"[head_scan] skipped due to error: {e_scan}\")\n",
    "            head_scan_summary = {\"error\": str(e_scan)}\n",
    "\n",
    "    # Run enhanced morphemic analysis with metaphor validation\n",
    "    results = run_welfare_morphemic_analysis(model, tokenizer)\n",
    "    if isinstance(results, dict) and head_scan_summary is not None:\n",
    "        results[\"head_scan\"] = head_scan_summary\n",
    "\n",
    "    # Create enhanced visualization\n",
    "    try:\n",
    "        print(f\"\\nGenerating comprehensive research visualization...\")\n",
    "        fig = create_enhanced_demo_visualization(results, show_brachistochrone=True)\n",
    "        # Save artifacts for reproducibility (Colab- and local-friendly)\n",
    "        try:\n",
    "            try:\n",
    "                demo_dir = os.path.dirname(__file__)\n",
    "            except NameError:\n",
    "                demo_dir = os.getcwd()\n",
    "            if fig is not None:\n",
    "                fig_path = os.path.join(demo_dir, \"thoughtpath.png\")\n",
    "                fig.savefig(fig_path, dpi=180, bbox_inches=\"tight\")\n",
    "                print(f\"Saved visualization to {fig_path}\")\n",
    "                # Also save with legacy/demo-friendly name seen in prior transcripts\n",
    "                unknown_path = os.path.join(demo_dir, \"morphemic.png\")\n",
    "                try:\n",
    "                    fig.savefig(unknown_path, dpi=180, bbox_inches=\"tight\")\n",
    "                    print(f\"Saved visualization to {unknown_path}\")\n",
    "                except Exception as _e_save_alt:\n",
    "                    print(f\"Secondary save skipped: {unknown_path} ({_e_save_alt})\")\n",
    "            md_path = os.path.join(demo_dir, \"result.md\")\n",
    "            with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(format_results_markdown(results))\n",
    "            print(f\"Wrote summary to {md_path}\")\n",
    "        except Exception as e_save:\n",
    "            print(f\"Artifact saving skipped: {e_save}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Visualization generation failed: {e}\")\n",
    "        # Attempt basic visualization\n",
    "        try:\n",
    "            fig2 = create_enhanced_demo_visualization(results, show_brachistochrone=False)\n",
    "            try:\n",
    "                try:\n",
    "                    demo_dir = os.path.dirname(__file__)\n",
    "                except NameError:\n",
    "                    demo_dir = os.getcwd()\n",
    "                if fig2 is not None:\n",
    "                    fig_path = os.path.join(demo_dir, \"thoughtpath.png\")\n",
    "                    fig2.savefig(fig_path, dpi=180, bbox_inches=\"tight\")\n",
    "                    print(f\"Saved visualization to {fig_path}\")\n",
    "                    # Also save with legacy/demo-friendly name\n",
    "                    unknown_path = os.path.join(demo_dir, \"morphemic.png\")\n",
    "                    try:\n",
    "                        fig2.savefig(unknown_path, dpi=180, bbox_inches=\"tight\")\n",
    "                        print(f\"Saved visualization to {unknown_path}\")\n",
    "                    except Exception as _e_save_alt2:\n",
    "                        print(f\"Secondary save skipped: {unknown_path} ({_e_save_alt2})\")\n",
    "                md_path = os.path.join(demo_dir, \"result.md\")\n",
    "                with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(format_results_markdown(results))\n",
    "                print(f\"Wrote summary to {md_path}\")\n",
    "            except Exception as e_save2:\n",
    "                print(f\"Artifact saving skipped: {e_save2}\")\n",
    "        except Exception as e2:\n",
    "            print(f\"Basic visualization also failed: {e2}\")\n",
    "\n",
    "    # Coverage verification (theory → code)\n",
    "    try:\n",
    "        coverage = verify_math_coverage(results)\n",
    "        if isinstance(results, dict):\n",
    "            results[\"theory_coverage\"] = coverage\n",
    "    except Exception as e_cov:\n",
    "        print(f\"Coverage check failed: {e_cov}\")\n",
    "\n",
    "    # Print concise interpretation notes for reviewers\n",
    "    try:\n",
    "        print(\"\\nInterpretation Notes\")\n",
    "        print(\"-\" * 19)\n",
    "        print(get_demo_explanation_text())\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Memory cleanup\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"\\nEnhanced research 00_Framework analysis completed\")\n",
    "    print(f\"Framework ready for continued investigation and validation\")\n",
    "\n",
    "    return results"
   ],
   "id": "524bebe719b11cab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# =========================================================================\n",
    "# HEAD SCAN HELPERS (AC per-head metrics and narration)\n",
    "# ========================================================================="
   ],
   "id": "369b2ba0f6017061"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "\n",
    "### Function: compute_ac_maps_from_qk\n",
    "\n",
    "Mathematical Foundation:\n",
    "- AC resonance (Section 05.3): R = (QK^T) ⊙ (KQ^T)\n",
    "- Causal masking: lower-triangular structure enforces autoregressive validity\n",
    "- Information measures: entropy and concentration as diagnostic proxies\n",
    "\n",
    "What It Computes:\n",
    "- Per-head maps: push attention, resonant agreement, and disagreement, plus summary metrics for entropy and resonance concentration.\n",
    "\n",
    "Connection to Theory:\n",
    "- References: 05.3 AC Attention; 04.1 RKHS (used elsewhere for stability)\n",
    "- Implements: Low-level AC diagnostics underpinning head scanning and evaluation\n",
    "\n",
    "Code:\n",
    "Implementation follows in the next code cell.\n",
    "\n",
    "Expected Output:\n",
    "- Tuple of numpy arrays (A_push, A_resonant, A_diff) and a metrics dict.\n",
    "\n",
    "\"\"\""
   ],
   "id": "d5488df7774d1e5c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def compute_ac_maps_from_qk(Q: torch.Tensor, K: torch.Tensor, keep_mask_1T: Optional[torch.Tensor] = None,\n",
    "                             signed: bool = False) -> Tuple[np.ndarray, np.ndarray, np.ndarray, Dict[str, float]]:\n",
    "    \"\"\"Compute per-head AC maps with bidirectional resonance and basic metrics.\n",
    "    Returns (A_push, A_resonant, A_diff, metrics) where each array is float32 on CPU.\n",
    "    metrics: { 'push_entropy_bits': float, 'resonance_concentration': float }\n",
    "    \"\"\"\n",
    "    Q = Q.to(torch.float32)\n",
    "    K = K.to(torch.float32)\n",
    "    T, Dh = Q.shape\n",
    "    scale = 1.0 / math.sqrt(max(1, Dh))\n",
    "\n",
    "    # Build causal and token-keep masks\n",
    "    device = Q.device\n",
    "    causal_mask = torch.tril(torch.ones(T, T, device=device, dtype=torch.bool))\n",
    "    if keep_mask_1T is not None:\n",
    "        token_mask = keep_mask_1T.bool().unsqueeze(-1) & keep_mask_1T.bool().unsqueeze(-2)\n",
    "        full_mask = causal_mask & token_mask.squeeze(0)\n",
    "    else:\n",
    "        full_mask = causal_mask\n",
    "\n",
    "    # Push attention\n",
    "    push_logits = (Q @ K.T) * scale\n",
    "    push_logits = push_logits.masked_fill(~full_mask, float(\"-inf\"))\n",
    "    if signed:\n",
    "        A_push = F.elu(push_logits) + 1\n",
    "        A_push = A_push / (A_push.sum(dim=-1, keepdim=True) + 1e-12)\n",
    "    else:\n",
    "        A_push = F.softmax(push_logits, dim=-1)\n",
    "\n",
    "    # Pull attention\n",
    "    pull_logits = (K @ Q.T) * scale\n",
    "    pull_logits = pull_logits.masked_fill(~full_mask, float(\"-inf\"))\n",
    "    if signed:\n",
    "        A_pull = F.elu(pull_logits) + 1\n",
    "        A_pull = A_pull / (A_pull.sum(dim=-1, keepdim=True) + 1e-12)\n",
    "    else:\n",
    "        A_pull = F.softmax(pull_logits, dim=-1)\n",
    "\n",
    "    # Resonance and disagreement\n",
    "    A_resonant = A_push * A_pull.T\n",
    "    A_diff = (A_push - A_pull.T).abs()\n",
    "\n",
    "    # Metrics (use numpy for stability)\n",
    "    eps = 1e-12\n",
    "    push_np = A_push.to(torch.float64).clamp_min(eps).detach().cpu().numpy()\n",
    "    reson_np = A_resonant.to(torch.float64).clamp_min(eps).detach().cpu().numpy()\n",
    "\n",
    "    push_entropy = float(-(push_np * np.log2(push_np)).sum())\n",
    "    s1 = reson_np.sum()\n",
    "    if s1 > 0:\n",
    "        concentration = float(((reson_np ** 2).sum() / (s1 * s1 + eps)) * reson_np.size)\n",
    "    else:\n",
    "        concentration = 0.0\n",
    "\n",
    "    return (\n",
    "        A_push.to(torch.float32).cpu().numpy(),\n",
    "        A_resonant.to(torch.float32).cpu().numpy(),\n",
    "        A_diff.to(torch.float32).cpu().numpy(),\n",
    "        {\"push_entropy_bits\": push_entropy, \"resonance_concentration\": concentration},\n",
    "    )"
   ],
   "id": "519264367c0e861a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "### Function: head_scan_and_rank\n",
    "\n",
    "Mathematical Foundation:\n",
    "- AC resonance and disagreement (Section 05.3)\n",
    "- RKHS symmetric operator S = H_{qk}H_{kq} eigengap as stability diagnostic (Section 04.1)\n",
    "\n",
    "What It Computes:\n",
    "- Scans a window of layers, computes per-head AC metrics and RKHS S eigengap, and ranks heads for follow-up analysis/visualization.\n",
    "\n",
    "Connection to Theory:\n",
    "- References: 04.1 RKHS, 05.3 AC Attention\n",
    "- Implements: Practical selection of high-signal heads for validation and narrative plots\n",
    "\n",
    "Code:\n",
    "Implementation follows in the next code cell.\n",
    "\n",
    "Expected Output:\n",
    "- List of dicts with per-head metrics and rankings.\n",
    "\"\"\""
   ],
   "id": "519bea02ebf845b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def head_scan_and_rank(model: AutoModelForCausalLM, tokenizer: AutoTokenizer, prompt: str,\n",
    "                        layer_window: Optional[Tuple[int, int]] = None, top_k: int = 3,\n",
    "                        lambda_reg: float = 1e-3) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Scan a window of layers, compute per-head resonance metrics and RKHS S eigengap, and rank heads.\n",
    "    Returns a list of dicts with fields: layer, head, resonance_concentration, push_entropy_bits,\n",
    "    disagreement_velocity, eigengap_S, T.\n",
    "    \"\"\"\n",
    "    # Determine model structure\n",
    "    try:\n",
    "        if hasattr(model, 'model') and hasattr(model.model, 'layers'):\n",
    "            total_layers = len(model.model.layers)\n",
    "            num_heads = model.config.num_attention_heads\n",
    "        elif hasattr(model, 'transformer') and hasattr(model.transformer, 'h'):\n",
    "            total_layers = len(model.transformer.h)\n",
    "            num_heads = model.config.num_attention_heads\n",
    "        else:\n",
    "            total_layers = 12\n",
    "            num_heads = getattr(model.config, 'num_attention_heads', 8)\n",
    "    except Exception:\n",
    "        total_layers = 12\n",
    "        num_heads = getattr(model.config, 'num_attention_heads', 8)\n",
    "\n",
    "    # Determine scan window\n",
    "    if layer_window is None:\n",
    "        start = total_layers // 3\n",
    "        end = 2 * total_layers // 3\n",
    "    else:\n",
    "        start, end = int(layer_window[0]), int(layer_window[1])\n",
    "    scan_layers = list(range(max(0, start), min(total_layers - 1, end) + 1))\n",
    "\n",
    "    # Tokenize prompt\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\",\n",
    "                       max_length=MORPHEMIC_CONFIG[\"max_sequence_length\"], truncation=True).to(model.device)\n",
    "\n",
    "    ranked: List[Dict[str, Any]] = []\n",
    "    for layer in scan_layers:\n",
    "        try:\n",
    "            with torch.no_grad(), capture_semantic_data(model, layer):\n",
    "                _ = model(**inputs)\n",
    "        except Exception as e:\n",
    "            print(f\"[head_scan] Layer {layer} capture error: {e}\")\n",
    "            continue\n",
    "\n",
    "        Q_all = _CAPTURED_LAYER_STATE.get(\"Q_all\")\n",
    "        K_all = _CAPTURED_LAYER_STATE.get(\"K_all\")\n",
    "        keep = _CAPTURED_LAYER_STATE.get(\"keep_1T\")\n",
    "        if Q_all is None or K_all is None:\n",
    "            print(f\"[head_scan] Layer {layer} has no Q/K captured\")\n",
    "            continue\n",
    "\n",
    "        H, T, Dh = Q_all.shape\n",
    "        KV = K_all.shape[0]\n",
    "        kv_groups = max(1, H // max(1, KV))\n",
    "\n",
    "        for head in range(min(num_heads, H)):\n",
    "            try:\n",
    "                kv_idx = head // kv_groups\n",
    "                Qh = Q_all[head]\n",
    "                Kh = K_all[min(kv_idx, KV - 1)]\n",
    "\n",
    "                A_push, A_resonant, A_diff, metrics = compute_ac_maps_from_qk(Qh, Kh, keep)\n",
    "\n",
    "                # Disagreement velocity\n",
    "                diff = (Qh @ Kh.T) - (Kh @ Qh.T)\n",
    "                # normalize by token count squared\n",
    "                dv = float((diff.to(torch.float32) ** 2).sum().item() / (T * T + 1e-8))\n",
    "\n",
    "                # RKHS S eigengap per head\n",
    "                Qh32 = Qh.to(torch.float32)\n",
    "                Kh32 = Kh.to(torch.float32)\n",
    "                Kkk = Kh32 @ Kh32.t()\n",
    "                Kqq = Qh32 @ Qh32.t()\n",
    "                I_k = torch.eye(Kkk.shape[0], device=Kkk.device, dtype=Kkk.dtype)\n",
    "                I_q = torch.eye(Kqq.shape[0], device=Kqq.device, dtype=Kqq.dtype)\n",
    "                lam = torch.tensor(lambda_reg, device=Qh32.device, dtype=Qh32.dtype)\n",
    "                try:\n",
    "                    H_qk = (Qh32 @ Kh32.t()) @ torch.linalg.solve(Kkk + lam * I_k, I_k)\n",
    "                    H_kq = (Kh32 @ Qh32.t()) @ torch.linalg.solve(Kqq + lam * I_q, I_q)\n",
    "                    S_h = H_qk @ H_kq\n",
    "                    S_sym = 0.5 * (S_h + S_h.t())\n",
    "                    # Use eigvalsh for symmetric matrices\n",
    "                    evals = torch.linalg.eigvalsh(S_sym.cpu())\n",
    "                    if evals.numel() >= 2:\n",
    "                        eigengap = float((evals[-1] - evals[-2]).item())\n",
    "                    else:\n",
    "                        eigengap = 0.0\n",
    "                except Exception:\n",
    "                    eigengap = 0.0\n",
    "\n",
    "                ranked.append({\n",
    "                    \"layer\": int(layer),\n",
    "                    \"head\": int(head),\n",
    "                    \"resonance_concentration\": float(metrics[\"resonance_concentration\"]),\n",
    "                    \"push_entropy_bits\": float(metrics[\"push_entropy_bits\"]),\n",
    "                    \"disagreement_velocity\": float(dv),\n",
    "                    \"eigengap_S\": float(eigengap),\n",
    "                    \"T\": int(T),\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"[head_scan] L{layer} H{head} error: {e}\")\n",
    "                continue\n",
    "\n",
    "    # Rank results\n",
    "    def sort_key(r):\n",
    "        return (\n",
    "            -r.get(\"resonance_concentration\", 0.0),\n",
    "            r.get(\"disagreement_velocity\", 1e9),\n",
    "            -r.get(\"eigengap_S\", 0.0),\n",
    "        )\n",
    "\n",
    "    ranked.sort(key=sort_key)\n",
    "    return ranked[:max(1, int(top_k))]\n",
    "\n"
   ],
   "id": "e6b07b269f943f20"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"### Function: print_didactic_head_narration\n",
    "\n",
    "Purpose:\n",
    "- Emit a concise narrative that ties prompt, AC resonance, and RKHS metrics to selected heads for reviewer readability.\n",
    "\n",
    "Inputs/Outputs:\n",
    "- Input: head_results list from head_scan_and_rank, original prompt, top_k.\n",
    "- Output: prints a didactic report; no return.\n",
    "\n",
    "\"\"\""
   ],
   "id": "a58ec84dd8ccd5b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def print_didactic_head_narration(head_results: List[Dict[str, Any]], prompt: str, top_k: int = 3) -> None:\n",
    "    \"\"\"Print Option‑2 didactic narration using scan results.\"\"\"\n",
    "    print(\"\\nDidactic Head Discovery (Prompt → Scan → Evidence)\")\n",
    "    print(\"-\" * 65)\n",
    "    print(\"1) Prompt → tokens\")\n",
    "    print(f\"   We tokenize: \\\"{prompt}\\\" and analyze mid/late layers.\")\n",
    "\n",
    "    print(\"\\n2) Bidirectional attention and resonance\")\n",
    "    print(\"   A_push = softmax(QK^T), A_pull = softmax(KQ^T), resonance R = A_push ⊙ A_pull^T.\")\n",
    "    print(\"   Intuition: R highlights positions where forward and reverse attention agree.\")\n",
    "\n",
    "    print(\"\\n3) RKHS symmetric operator S\")\n",
    "    print(\"   S = H_qk(λ) H_kq(λ) with ridge regularization. Spectral cues (eigengap) indicate structure.\")\n",
    "\n",
    "    print(\"\\n4) Head scoring and selection\")\n",
    "    k = min(top_k, len(head_results))\n",
    "    top = head_results[:k]\n",
    "    if top:\n",
    "        summary = \", \".join([f\"L{r['layer']}H{r['head']} ({r['resonance_concentration']:.2f})\" for r in top])\n",
    "        print(f\"   Top-{k} heads: [{summary}]\")\n",
    "\n",
    "    if top:\n",
    "        r0 = top[0]\n",
    "        print(\"\\n5) Evidence card (Top-1 head)\")\n",
    "        print(f\"   - Head: L{r0['layer']} H{r0['head']}\")\n",
    "        print(f\"   - Resonance concentration: {r0['resonance_concentration']:.3f}\")\n",
    "        print(f\"   - AC disagreement velocity: {r0['disagreement_velocity']:.4f}\")\n",
    "        print(f\"   - S eigengap: {r0['eigengap_S']:.3f}\")\n",
    "        print(\"   - Note: α=0 parity (equivalence check); α>0 enables mutual verification.\")\n",
    "\n",
    "    print(\"\\n6) Interpretation\")\n",
    "    print(\"   The top head is the most responsible for output tokens under the agreement+RKHS diagnostic bundle.\")\n",
    "    print(\"   See 03.3 for methodology and 06 for evaluation protocols.\")\n"
   ],
   "id": "1ab04cae4d3f1a08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# =========================================================================\n",
    "# __main__ guard\n",
    "# =========================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_anthropic_demo()"
   ],
   "id": "17395f181ce6aa58"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
